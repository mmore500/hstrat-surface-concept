{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import functools\n",
    "import itertools as it\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "from hstrat import _auxiliary_lib as hstrat_aux\n",
    "import interval_search as inch\n",
    "from IPython.core.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import opytional as opyt\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from scipy import stats as scipy_stats\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pylib\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(funcName)s:%(lineno)d] %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Implement `get_ingest_site_at_rank`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1a: Prepare Support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_sites_reserved_per_incidence_at_rank(rank: int) -> int:\n",
    "    return pylib.bit_ceil(\n",
    "        pylib.hanoi.get_max_hanoi_value_through_index(rank) + 1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_num_sites_reserved_per_incidence_at_rank\n",
    "assert [\n",
    "    get_num_sites_reserved_per_incidence_at_rank(rank) for rank in range(17)\n",
    "] == [\n",
    "    # hanoi sequence (1-based):\n",
    "    1,  # 1,\n",
    "    2,  # 2,\n",
    "    2,  # 1,\n",
    "    4,  # 3,\n",
    "    4,  # 1,\n",
    "    4,  # 2,\n",
    "    4,  # 1,\n",
    "    4,  # 4,\n",
    "    4,  # 1,\n",
    "    4,  # 2,\n",
    "    4,  # 1,\n",
    "    4,  # 3,\n",
    "    4,  # 1,\n",
    "    4,  # 2,\n",
    "    4,  # 1,\n",
    "    8,  # 5,\n",
    "    8,  # 1,\n",
    "]\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pylib.log_args_and_result(logger, logging.DEBUG)\n",
    "def get_num_incidence_reservations_at_rank(\n",
    "    rank: int, surface_size: int\n",
    ") -> int:\n",
    "    reservation_size = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "    assert surface_size % reservation_size == 0\n",
    "    num_reservations = surface_size // reservation_size\n",
    "    return num_reservations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_num_incidence_reservations_at_rank\n",
    "assert [\n",
    "    get_num_incidence_reservations_at_rank(rank, 64) for rank in range(17)\n",
    "] == [\n",
    "    # hanoi sequence (1-based):\n",
    "    64,  # 1,\n",
    "    32,  # 2,\n",
    "    32,  # 1,\n",
    "    16,  # 3,\n",
    "    16,  # 1,\n",
    "    16,  # 2,\n",
    "    16,  # 1,\n",
    "    16,  # 4,\n",
    "    16,  # 1,\n",
    "    16,  # 2,\n",
    "    16,  # 1,\n",
    "    16,  # 3,\n",
    "    16,  # 1,\n",
    "    16,  # 2,\n",
    "    16,  # 1,\n",
    "    8,   # 5,\n",
    "    8,   # 1,\n",
    "]\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surface_rank_capacity(surface_size: int) -> int:\n",
    "    return pylib.hanoi.get_index_of_hanoi_value_nth_incidence(surface_size, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surface_size_exp in range(2, 12):\n",
    "    surface_size = 2**surface_size_exp\n",
    "    get_num_incidence_reservations_at_rank(\n",
    "        get_surface_rank_capacity(surface_size) - 1,\n",
    "        surface_size,\n",
    "    )\n",
    "    with pytest.raises(AssertionError):\n",
    "        get_num_incidence_reservations_at_rank(\n",
    "            get_surface_rank_capacity(surface_size),\n",
    "            surface_size,\n",
    "        )\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_2x_reservation_eligible(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> bool:\n",
    "    reservation_width = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "    lb_inclusive = (\n",
    "        pylib.hanoi.get_max_hanoi_value_through_index(rank)\n",
    "        - reservation_width // 2\n",
    "        + 1\n",
    "    )\n",
    "    ub_exclusive = reservation_width // 2\n",
    "    return lb_inclusive <= hanoi_value < ub_exclusive\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hanoi_invader(hanoi_value: int, rank: int) -> bool:\n",
    "    reservation_width = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "    return hanoi_value >= reservation_width // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_hanoi_invader(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert is_hanoi_invader(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "\n",
    "assert not is_hanoi_invader(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "\n",
    "assert not is_hanoi_invader(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hanoi_invaded(hanoi_value: int, rank: int) -> bool:\n",
    "    reservation_width = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "    max_hanoi_value = pylib.hanoi.get_max_hanoi_value_through_index(rank)\n",
    "\n",
    "    return (\n",
    "        not is_hanoi_invader(hanoi_value, rank)\n",
    "        and max_hanoi_value >= hanoi_value + reservation_width // 2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_hanoi_invaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert is_hanoi_invaded(\n",
    "    0, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert not is_hanoi_invaded(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "\n",
    "assert not is_hanoi_invaded(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert is_hanoi_invaded(\n",
    "    0, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert not is_hanoi_invaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert is_hanoi_invaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(5, 0)\n",
    ")\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hanoi_invadable_and_uninvaded(hanoi_value: int, rank: int) -> bool:\n",
    "    return not is_hanoi_invader(hanoi_value, rank) and not is_hanoi_invaded(\n",
    "        hanoi_value, rank\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_hanoi_invadable_and_uninvaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    2, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    0, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(2, 0)\n",
    ")\n",
    "assert is_hanoi_invadable_and_uninvaded(\n",
    "    3, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    0, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert is_hanoi_invadable_and_uninvaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(4, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    1, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(5, 0)\n",
    ")\n",
    "assert not is_hanoi_invadable_and_uninvaded(\n",
    "    5, pylib.hanoi.get_index_of_hanoi_value_nth_incidence(5, 0)\n",
    ")\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_hanoi_invader_values(hanoi_value: int) -> typing.Iterator[int]:\n",
    "    for i in it.count():\n",
    "        yield hanoi_value + pylib.bit_ceil(hanoi_value + 1) * 2**i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [*it.islice(iter_hanoi_invader_values(0), 6)] == [1, 2, 4, 8, 16, 32]\n",
    "assert [*it.islice(iter_hanoi_invader_values(3), 4)] == [7, 11, 19, 35]\n",
    "assert [*it.islice(iter_hanoi_invader_values(8), 2)] == [24, 40]\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hanoi_value_filled_first_reservation_layer(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    "):\n",
    "    first_instance_index = pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "        hanoi_value, 0\n",
    "    )\n",
    "    if first_instance_index >= get_surface_rank_capacity(surface_size):\n",
    "        return False\n",
    "\n",
    "    first_layer_size = get_num_incidence_reservations_at_rank(\n",
    "        pylib.hanoi.get_index_of_hanoi_value_nth_incidence(hanoi_value, 0),\n",
    "        surface_size,\n",
    "    )\n",
    "    return not (\n",
    "        pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "            hanoi_value,\n",
    "            rank,\n",
    "        )\n",
    "        < first_layer_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upcoming_hanoi_invasion_value(hanoi_value: int, rank: int) -> int:\n",
    "    rank = max(\n",
    "        rank,\n",
    "        pylib.hanoi.get_index_of_hanoi_value_nth_incidence(hanoi_value, 0),\n",
    "    )\n",
    "\n",
    "    reservation_width = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "    if is_hanoi_invader(hanoi_value, rank) or is_hanoi_invaded(\n",
    "        hanoi_value, rank\n",
    "    ):\n",
    "        return hanoi_value + reservation_width\n",
    "    else:\n",
    "        return hanoi_value + reservation_width // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upcoming_hanoi_invasion_rank(hanoi_value: int, rank: int) -> int:\n",
    "    upcoming_invasion_hanoi_value = get_upcoming_hanoi_invasion_value(\n",
    "        hanoi_value, rank\n",
    "    )\n",
    "    upcoming_invasion_rank = (\n",
    "        pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "            upcoming_invasion_hanoi_value, 0\n",
    "        )\n",
    "    )\n",
    "    return upcoming_invasion_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_mx(hanoi_value: int, rank: int) -> int:\n",
    "    if is_hanoi_invadable_and_uninvaded(hanoi_value, rank):\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_num_reservations_available(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> int:\n",
    "    mx = get_regime_mx(hanoi_value, rank)\n",
    "    return get_num_incidence_reservations_at_rank(rank, surface_size) * mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_downgrade_rank(\n",
    "    cycle_num_ranks: int,\n",
    "    required_cycle_rank_position: int,\n",
    "    required_lag: int,\n",
    "    end_rank: int,\n",
    "    hanoi_offset: int,\n",
    "    cadence_for_asserts: int,\n",
    "    hanoi_value_for_asserts: int,\n",
    "):\n",
    "\n",
    "    offset = hanoi_offset\n",
    "    hanoi_value = hanoi_value_for_asserts\n",
    "\n",
    "    assert cadence_for_asserts\n",
    "    cadence = cadence_for_asserts\n",
    "\n",
    "    assert cycle_num_ranks\n",
    "    assert required_cycle_rank_position < cycle_num_ranks\n",
    "    assert required_lag % cadence == 0\n",
    "    # oc is offset corrected\n",
    "    end_rank_oc = end_rank - offset\n",
    "\n",
    "    deadline_rank_oc = end_rank_oc - required_lag\n",
    "    #\n",
    "    #    tt_below |             | goal\n",
    "    #########################################################\n",
    "    #             |----tour time----|\n",
    "    #             |             :   |\n",
    "    #                                           ^ end_rank\n",
    "    #                              ^deadline rank\n",
    "    #               ^mapped to here (intermediate)\n",
    "    #             ^ then to here\n",
    "    #                            ^ then to here\n",
    "    #\n",
    "    #########################################################\n",
    "    #             |----tour time----|\n",
    "    #             |             :   |          :  |\n",
    "    #                                                    ^ end_rank\n",
    "    #                                         ^deadline rank\n",
    "    #                              ^mapped to here (intermediate)\n",
    "    #             ^ then to here\n",
    "    #                           ^ then to here\n",
    "    #\n",
    "    intermediate_oc = deadline_rank_oc - required_cycle_rank_position\n",
    "    assert deadline_rank_oc - intermediate_oc <= cycle_num_ranks\n",
    "\n",
    "    tt_below_oc = intermediate_oc - pylib.modulo(\n",
    "        intermediate_oc, cycle_num_ranks\n",
    "    )\n",
    "    assert tt_below_oc % cadence == 0\n",
    "    assert tt_below_oc % cycle_num_ranks == 0\n",
    "    assert (\n",
    "        deadline_rank_oc - tt_below_oc\n",
    "        <= cycle_num_ranks + required_cycle_rank_position\n",
    "    )\n",
    "\n",
    "    goal_oc = tt_below_oc + required_cycle_rank_position\n",
    "    assert goal_oc % cycle_num_ranks == required_cycle_rank_position\n",
    "    assert goal_oc % cadence == 0\n",
    "    assert goal_oc <= deadline_rank_oc\n",
    "    assert goal_oc - deadline_rank_oc <= cycle_num_ranks\n",
    "\n",
    "    downgrade_rank_oc = goal_oc\n",
    "    downgrade_rank = goal_oc + offset\n",
    "    assert downgrade_rank <= end_rank\n",
    "    assert (\n",
    "        required_lag\n",
    "        <= end_rank - downgrade_rank\n",
    "        <= cycle_num_ranks + required_lag\n",
    "    )\n",
    "\n",
    "    assert cycle_num_ranks % cadence == 0\n",
    "    assert (\n",
    "        pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "            hanoi_value, offset\n",
    "        )\n",
    "    ) % cycle_num_ranks == 1\n",
    "    assert (\n",
    "        pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "            hanoi_value, offset + cadence\n",
    "        )\n",
    "    ) % cycle_num_ranks == 2\n",
    "\n",
    "    assert cycle_num_ranks % cadence == 0\n",
    "    if tt_below_oc + offset >= 0:\n",
    "        assert tt_below_oc % cadence == 0\n",
    "        assert tt_below_oc % cycle_num_ranks == 0\n",
    "        assert (\n",
    "            pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "                hanoi_value, tt_below_oc + offset\n",
    "            )\n",
    "            - 1\n",
    "        ) % (cycle_num_ranks // cadence) == 0\n",
    "    if downgrade_rank >= 0:\n",
    "        assert (downgrade_rank + cadence - offset) % cadence == 0\n",
    "        assert (\n",
    "            pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "                hanoi_value, downgrade_rank\n",
    "            )\n",
    "            - 1\n",
    "        ) % (cycle_num_ranks // cadence) == (\n",
    "            required_cycle_rank_position // cadence\n",
    "        )\n",
    "\n",
    "    return downgrade_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_reservation_downgrade_rank(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> int:\n",
    "    cadence = pylib.hanoi.get_hanoi_value_index_cadence(hanoi_value)\n",
    "    offset = pylib.hanoi.get_hanoi_value_index_offset(hanoi_value)\n",
    "    big_tour_size = get_regime_num_reservations_available(\n",
    "        hanoi_value,\n",
    "        surface_size,\n",
    "        rank,\n",
    "    )\n",
    "    if big_tour_size == 1:\n",
    "        return sys.maxsize\n",
    "    big_tour_time = big_tour_size * cadence\n",
    "    end_rank = get_upcoming_hanoi_invasion_rank(hanoi_value, rank)\n",
    "    assert end_rank\n",
    "\n",
    "    cycle_num_ranks = big_tour_time\n",
    "    required_cycle_rank_position = big_tour_time // 2 - cadence\n",
    "    assert required_cycle_rank_position % cadence == 0\n",
    "    assert required_cycle_rank_position < cycle_num_ranks\n",
    "    required_lag = big_tour_time // 2\n",
    "    assert required_lag % cadence == 0\n",
    "\n",
    "    downgrade_rank = get_safe_downgrade_rank(\n",
    "        cycle_num_ranks=cycle_num_ranks,\n",
    "        required_cycle_rank_position=required_cycle_rank_position,\n",
    "        required_lag=required_lag,\n",
    "        end_rank=end_rank,\n",
    "        hanoi_offset=offset,\n",
    "        cadence_for_asserts=cadence,\n",
    "        hanoi_value_for_asserts=hanoi_value,\n",
    "    )\n",
    "    assert downgrade_rank <= end_rank\n",
    "    return downgrade_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractional_downgrade_state(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> typing.Dict:\n",
    "    for invading_hanoi_value in iter_hanoi_invader_values(hanoi_value):\n",
    "        if invading_hanoi_value >= 2**surface_size // 2:\n",
    "            return None\n",
    "        if not has_hanoi_value_filled_first_reservation_layer(\n",
    "            invading_hanoi_value, surface_size, rank\n",
    "        ):\n",
    "            break\n",
    "\n",
    "    assert invading_hanoi_value > hanoi_value\n",
    "\n",
    "    for attempt in 1, 2:\n",
    "        invader_cadence = pylib.hanoi.get_hanoi_value_index_cadence(\n",
    "            invading_hanoi_value\n",
    "        )\n",
    "        protagonist_cadence = pylib.hanoi.get_hanoi_value_index_cadence(\n",
    "            hanoi_value\n",
    "        )\n",
    "\n",
    "        if invading_hanoi_value > surface_size // 2:\n",
    "            return None\n",
    "\n",
    "        invasion_rank = pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "            invading_hanoi_value, 0\n",
    "        )\n",
    "        num_reservations = get_num_incidence_reservations_at_rank(\n",
    "            invasion_rank, surface_size\n",
    "        )\n",
    "        if num_reservations == 1:\n",
    "            return None\n",
    "\n",
    "        tour_size = 2 * num_reservations\n",
    "\n",
    "        protagonist_tour_time = tour_size * protagonist_cadence\n",
    "        num_protagonist_cycles_per_invader_cadence = (\n",
    "            invader_cadence // protagonist_tour_time\n",
    "        )\n",
    "        if num_protagonist_cycles_per_invader_cadence >= (\n",
    "            # see test_calc_dyadic_lcm_upper_bound.py\n",
    "            # https://github.com/mmore500/hstrat-surface-concept/blob/4d0eca2ae3fe1890983889fdb8a8482fd3b24627/pylib/test/test_calc_dyadic_lcm_upper_bound.py#L39\n",
    "            4\n",
    "            * tour_size\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        if attempt == 1 and invasion_rank <= rank:\n",
    "            invading_hanoi_value = (\n",
    "                hanoi_value + (invading_hanoi_value - hanoi_value) * 2\n",
    "            )\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # see test_calc_dyadic_lcm_upper_bound.py\n",
    "    # https://github.com/mmore500/hstrat-surface-concept/blob/4d0eca2ae3fe1890983889fdb8a8482fd3b24627/pylib/test/test_calc_dyadic_lcm_upper_bound.py#L39\n",
    "    # num_granules * tour_size * 2 == num_protagonist_cycles_per_invader_cadence\n",
    "    # num_granules == num_protagonist_cycles_per_invader_cadence // (tour_size * 2)\n",
    "    num_granules = min(\n",
    "        num_protagonist_cycles_per_invader_cadence // (tour_size * 2),\n",
    "        num_reservations,\n",
    "    )\n",
    "    assert 1 < num_granules <= num_reservations, (\n",
    "        num_granules,\n",
    "        num_reservations,\n",
    "    )\n",
    "    granule_size = num_reservations // num_granules\n",
    "    assert granule_size\n",
    "\n",
    "    raw_current_subtrahend = (\n",
    "        pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "            invading_hanoi_value,\n",
    "            rank,\n",
    "        )\n",
    "    )\n",
    "    raw_next_subtrahend = raw_current_subtrahend + 1\n",
    "\n",
    "    current_subtrahend_granule = (\n",
    "        raw_current_subtrahend + granule_size - 1\n",
    "    ) // granule_size\n",
    "    assert current_subtrahend_granule <= raw_current_subtrahend\n",
    "    assert bool(current_subtrahend_granule) == bool(raw_current_subtrahend)\n",
    "\n",
    "    next_subtrahend_granule = (\n",
    "        raw_next_subtrahend + granule_size - 1\n",
    "    ) // granule_size\n",
    "    assert next_subtrahend_granule <= raw_next_subtrahend\n",
    "    assert bool(next_subtrahend_granule) == bool(raw_next_subtrahend)\n",
    "\n",
    "    granularized_current_subtrahend = current_subtrahend_granule * granule_size\n",
    "    assert granularized_current_subtrahend >= raw_current_subtrahend\n",
    "\n",
    "    granularized_next_subtrahend = next_subtrahend_granule * granule_size\n",
    "    assert granularized_next_subtrahend >= raw_next_subtrahend\n",
    "\n",
    "    assert (\n",
    "        0\n",
    "        <= granularized_current_subtrahend\n",
    "        <= granularized_next_subtrahend\n",
    "        <= num_reservations\n",
    "    )\n",
    "\n",
    "    upcoming_invader_rank = (\n",
    "        pylib.hanoi.get_index_of_hanoi_value_next_incidence(\n",
    "            invading_hanoi_value, rank\n",
    "        )\n",
    "    )\n",
    "    assert upcoming_invader_rank > rank\n",
    "    return {\n",
    "        \"hanoi value\": hanoi_value,\n",
    "        \"hanoi cadence\": protagonist_cadence,\n",
    "        \"upcoming invader rank\": upcoming_invader_rank,\n",
    "        \"first invasion rank\": invasion_rank,\n",
    "        \"invader cadence\": invader_cadence,\n",
    "        \"invading hanoi value\": invading_hanoi_value,\n",
    "        \"current subtrahend\": granularized_current_subtrahend,\n",
    "        \"next subtrahend\": granularized_next_subtrahend,\n",
    "        \"tour size\": tour_size,\n",
    "        \"num granules\": num_granules,\n",
    "        \"granule size\": granule_size,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractional_downgrade_rank(\n",
    "    hanoi_value: int,\n",
    "    surface_size: int,\n",
    "    rank: int,\n",
    "    fractional_downgrade_state: typing.Dict,\n",
    ") -> int:\n",
    "    state = fractional_downgrade_state\n",
    "\n",
    "    cadence = pylib.hanoi.get_hanoi_value_index_cadence(hanoi_value)\n",
    "    offset = pylib.hanoi.get_hanoi_value_index_offset(hanoi_value)\n",
    "    big_tour_size = pylib.calc_dyadic_lcm_upper_bound(\n",
    "        state[\"tour size\"] - state[\"current subtrahend\"],\n",
    "        state[\"tour size\"] - state[\"next subtrahend\"],\n",
    "    )\n",
    "\n",
    "    if state[\"tour size\"] == 1:\n",
    "        return sys.maxsize\n",
    "    big_tour_time = big_tour_size * cadence\n",
    "    end_rank = state[\"upcoming invader rank\"]\n",
    "    assert end_rank\n",
    "\n",
    "    cycle_num_ranks = big_tour_time\n",
    "    required_cycle_rank_position = 0\n",
    "\n",
    "    assert required_cycle_rank_position % cadence == 0\n",
    "    assert required_cycle_rank_position < cycle_num_ranks\n",
    "    required_lag = (state[\"tour size\"] - state[\"next subtrahend\"]) * cadence\n",
    "    assert required_lag % cadence == 0\n",
    "    res = get_safe_downgrade_rank(\n",
    "        cycle_num_ranks=cycle_num_ranks,\n",
    "        required_cycle_rank_position=required_cycle_rank_position,\n",
    "        required_lag=required_lag,\n",
    "        end_rank=end_rank,\n",
    "        hanoi_offset=offset,\n",
    "        cadence_for_asserts=cadence,\n",
    "        hanoi_value_for_asserts=hanoi_value,\n",
    "    )\n",
    "\n",
    "    assert res > state[\"upcoming invader rank\"] - state[\"invader cadence\"]\n",
    "    assert res <= state[\"upcoming invader rank\"]\n",
    "    assert res > 0\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractional_downgrade_num_reservations_provided(\n",
    "    hanoi_value: int,\n",
    "    surface_size: int,\n",
    "    rank: int,\n",
    "    fractional_downgrade_state: typing.Dict,\n",
    ") -> int:\n",
    "    thresh = get_fractional_downgrade_rank(\n",
    "        hanoi_value,\n",
    "        surface_size,\n",
    "        rank,\n",
    "        fractional_downgrade_state,\n",
    "    )\n",
    "\n",
    "    state = fractional_downgrade_state\n",
    "    if rank >= thresh:\n",
    "        return state[\"tour size\"] - state[\"next subtrahend\"]\n",
    "    else:\n",
    "        return state[\"tour size\"] - state[\"current subtrahend\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_num_reservations_provided(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> int:\n",
    "    thresh = get_regime_reservation_downgrade_rank(\n",
    "        hanoi_value, surface_size, rank\n",
    "    )\n",
    "    before_thresh_num = get_regime_num_reservations_available(\n",
    "        hanoi_value,\n",
    "        surface_size,\n",
    "        rank,\n",
    "    )\n",
    "    if rank >= thresh:\n",
    "        return before_thresh_num // 2\n",
    "    else:\n",
    "        return before_thresh_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=8192)\n",
    "def get_num_reservations_provided(\n",
    "    hanoi_value: int, surface_size: int, rank: int\n",
    ") -> int:\n",
    "    fractional_downgrade_state = get_fractional_downgrade_state(\n",
    "        hanoi_value, surface_size, rank\n",
    "    )\n",
    "    if fractional_downgrade_state is not None:\n",
    "        return get_fractional_downgrade_num_reservations_provided(\n",
    "            hanoi_value,\n",
    "            surface_size,\n",
    "            rank,\n",
    "            fractional_downgrade_state,\n",
    "        )\n",
    "    else:\n",
    "        return get_regime_num_reservations_provided(\n",
    "            hanoi_value, surface_size, rank\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1b: Define `get_ingest_site_at_rank`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingest_site_at_rank(rank: int, surface_size: int) -> int:\n",
    "    if rank > get_surface_rank_capacity(surface_size):\n",
    "        raise ValueError(\n",
    "            f\"{surface_size}-bit surface only valid \"\n",
    "            \"through rank <= {get_surface_rank_capacity(surface_size)}, \"\n",
    "            f\"rank {rank} was requested\"\n",
    "        )\n",
    "\n",
    "    within_reservation_offset = pylib.hanoi.get_hanoi_value_at_index(rank)\n",
    "\n",
    "    num_incidence_reservations = get_num_reservations_provided(\n",
    "        within_reservation_offset, surface_size, rank\n",
    "    )\n",
    "\n",
    "    reservation_index = (\n",
    "        pylib.hanoi.get_hanoi_value_incidence_at_index(rank)\n",
    "        % num_incidence_reservations\n",
    "    )\n",
    "\n",
    "    longevity_ordered_reservation_position = (\n",
    "        # this is more correct in a theoretical sense, and does have some effect\n",
    "        # but actual functional improvements relative to simpler naive/alternating\n",
    "        # should be tested; it may not be worth the extra complexity\n",
    "        pylib.longevity_ordering_descending.get_longevity_mapped_position_of_index(\n",
    "            reservation_index,\n",
    "            surface_size,\n",
    "        )\n",
    "    )\n",
    "    if reservation_index == 0:\n",
    "        assert longevity_ordered_reservation_position == 0\n",
    "    elif reservation_index == pylib.bit_ceil(num_incidence_reservations) - 1:\n",
    "        assert longevity_ordered_reservation_position == (\n",
    "            surface_size // pylib.bit_ceil(num_incidence_reservations)\n",
    "        )\n",
    "\n",
    "    res = (\n",
    "        longevity_ordered_reservation_position\n",
    "        + within_reservation_offset\n",
    "    )\n",
    "    if rank == 0:\n",
    "        assert res == 0, {\n",
    "            \"longevity_ordered_reservation_position\": longevity_ordered_reservation_position,\n",
    "            \"reservation_index\": reservation_index,\n",
    "            \"surface_size\": surface_size,\n",
    "            \"within_reservation_offset\": within_reservation_offset,\n",
    "        }\n",
    "    assert res < surface_size\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: evaluate `get_ingest_site_at_rank`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2a: Unit Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_ingest_site_at_rank\n",
    "# **needs to be updated**\n",
    "# assert [get_ingest_site_at_rank(rank, 64) for rank in range(23)] == [\n",
    "#          # num_reservations\n",
    "#          #     # hanoi sequence (0-based):\n",
    "#     0,   # 64, # 0,\n",
    "#     1,   # 32, # 1,\n",
    "#     32,  # 32, # 0,\n",
    "#     2,   # 16, # 2,\n",
    "#     16,  # 16, # 0,\n",
    "#     33,  # 16, # 1,\n",
    "#     48,  # 16, # 0,\n",
    "#     3,   # 16, # 3,\n",
    "#     8,   # 16, # 0,\n",
    "#     17,  # 16, # 1,\n",
    "#     24,  # 16, # 0,\n",
    "#     34,  # 16, # 2,\n",
    "#     40,  # 16, # 0,\n",
    "#     49,  # 16, # 1,\n",
    "#     56,  # 16, # 0,\n",
    "#     4,   # 8,  # 4,\n",
    "#     0,   # 8,  # 0,\n",
    "#     9,   # 8,  # 1,\n",
    "#     32,  # 8,  # 0,\n",
    "#     18,  # 8,  # 2,\n",
    "#     16,  # 8,  # 0,\n",
    "#     25,  # 8,  # 1,\n",
    "#     48,  # 8,  # 0,\n",
    "# ]\n",
    "\n",
    "# assert [get_ingest_site_at_rank(rank, 16) for rank in range(21)] == [\n",
    "#         # num_reservations\n",
    "#         #     # hanoi sequence (0-based):\n",
    "#     0,  # 16, # 0,\n",
    "#     1,  # 8,  # 1,\n",
    "#     8,  # 8,  # 0,\n",
    "#     2,  # 4,  # 2,\n",
    "#     4,  # 4,  # 0,\n",
    "#     9,  # 4,  # 1,\n",
    "#     12, # 4,  # 0,\n",
    "#     3,  # 4,  # 3,\n",
    "#     0,  # 4,  # 0,\n",
    "#     5,  # 4,  # 1,\n",
    "#     8,  # 4,  # 0,\n",
    "#     10, # 4,  # 2,\n",
    "#     4,  # 4,  # 0,\n",
    "#     13, # 4,  # 1,\n",
    "#     12, # 4,  # 0,\n",
    "#     4,  # 2,  # 4,\n",
    "#     0,  # 2,  # 0,\n",
    "#     1,  # 2,  # 1,\n",
    "#     8,  # 2,  # 0,\n",
    "#     6,  # 2,  # 2,\n",
    "#     0,  # 2,  # 0,\n",
    "# ]\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2a: Integration Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surface_size_exp in range(3, 10, 2):\n",
    "    surface_size = 2**surface_size_exp\n",
    "    res = (\n",
    "        pylib.site_selection_eval.get_first_decreasing_hanoi_value_ingest(\n",
    "            get_ingest_site_at_rank,\n",
    "            surface_size=surface_size,\n",
    "            num_generations=min(\n",
    "                2**18, get_surface_rank_capacity(surface_size) - 1\n",
    "            ),\n",
    "            progress_wrap=tqdm,\n",
    "        )\n",
    "    )\n",
    "    assert res is None, res\n",
    "\n",
    "    res = pylib.site_selection_eval.get_first_ingest_over_too_new_site(\n",
    "        get_ingest_site_at_rank,\n",
    "        get_num_reservations_provided,\n",
    "        pylib.longevity_ordering_descending.get_longevity_mapped_position_of_index,\n",
    "        surface_size=surface_size,\n",
    "        num_generations=min(\n",
    "            2**18, get_surface_rank_capacity(surface_size) - 1\n",
    "        ),\n",
    "        progress_wrap=tqdm,\n",
    "    )\n",
    "    assert res is None, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2b: Visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surface_size_exp in range(3, 10, 2):\n",
    "    surface_size = 2**surface_size_exp\n",
    "    display(HTML(f\"<h3>surface size {surface_size}</h3>\"))\n",
    "\n",
    "    num_generations = min(\n",
    "        # don't run out of memory\n",
    "        2**18 if surface_size_exp < 7 else 2**12,\n",
    "        get_surface_rank_capacity(surface_size - 1),\n",
    "    )\n",
    "\n",
    "    surface_history_df = pylib.site_selection_eval.make_surface_history_df(\n",
    "        get_ingest_site_at_rank,\n",
    "        surface_size=surface_size,\n",
    "        num_generations=num_generations,\n",
    "        progress_wrap=tqdm,\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        ynorm=\"log\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_differentia_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        ynorm=\"linear\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_differentia_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        cnorm=\"log\",\n",
    "        ynorm=\"log\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_ingest_rank_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        cnorm=None,\n",
    "        ynorm=\"linear\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_ingest_rank_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_hanoi_value_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        teeplot_outattrs={\n",
    "            \"num-generations\": num_generations,\n",
    "            \"surface-size\": surface_size,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        ynorm=\"linear\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_hanoi_value_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        cnorm=\"log\",\n",
    "        ynorm=\"log\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_ingest_depth_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    kwargs = dict(\n",
    "        cnorm=\"log\",\n",
    "        ynorm=\"linear\",\n",
    "    )\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.site_ingest_depth_by_rank_heatmap,\n",
    "        surface_history_df,\n",
    "        **kwargs,\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                \"num-generations\": num_generations,\n",
    "                \"surface-size\": surface_size,\n",
    "            },\n",
    "            **kwargs,\n",
    "        },\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n",
    "\n",
    "    # ========================\n",
    "    pylib.tee_release(\n",
    "        pylib.site_selection_viz.stratum_persistence_dripplot,\n",
    "        surface_history_df[surface_history_df[\"rank\"] < 3000],\n",
    "        teeplot_outattrs={\n",
    "            \"num-generations\": num_generations,\n",
    "            \"surface-size\": surface_size,\n",
    "        },\n",
    "        progress_wrap=tqdm,\n",
    "        teeplot_subdir=\"05\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_size = 32\n",
    "num_generations = 300\n",
    "\n",
    "surface_history_df = pylib.site_selection_eval.make_surface_history_df(\n",
    "    get_ingest_site_at_rank,\n",
    "    surface_size,\n",
    "    num_generations,\n",
    "    tqdm,\n",
    ")\n",
    "\n",
    "\n",
    "# ========================\n",
    "def scatter_move_legend(*args, **kwargs) -> None:\n",
    "    ax = sns.scatterplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    )\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "pylib.tee_release(\n",
    "    scatter_move_legend,\n",
    "    data=surface_history_df,\n",
    "    x=\"rank\",\n",
    "    y=\"site\",\n",
    "    hue=\"ingest rank\",\n",
    "    teeplot_outattrs={\n",
    "        \"num-generations\": num_generations,\n",
    "        \"surface-size\": surface_size,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# ========================\n",
    "def scatter_invert(*args, **kwargs) -> None:\n",
    "    sns.scatterplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ).invert_yaxis()\n",
    "\n",
    "\n",
    "pylib.tee_release(\n",
    "    scatter_invert,\n",
    "    data=surface_history_df,\n",
    "    x=\"ingest rank\",\n",
    "    y=\"rank\",\n",
    "    hue=\"site\",\n",
    "    teeplot_outattrs={\n",
    "        \"num-generations\": num_generations,\n",
    "        \"surface-size\": surface_size,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# ========================\n",
    "def scatter_invert_zoom(*args, **kwargs) -> None:\n",
    "    ax = sns.scatterplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    )\n",
    "    ax.set_xlim([200, 250])\n",
    "    ax.set_ylim([200, 250])\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "pylib.tee_release(\n",
    "    scatter_invert_zoom,\n",
    "    data=surface_history_df,\n",
    "    x=\"ingest rank\",\n",
    "    y=\"rank\",\n",
    "    hue=\"site\",\n",
    "    teeplot_outattrs={\n",
    "        \"num-generations\": num_generations,\n",
    "        \"surface-size\": surface_size,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Implement `get_ingest_site_at_rank`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3a: Prepare Support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reservation_index_elimination_rank(\n",
    "    hanoi_value: int,\n",
    "    reservation_index: int,\n",
    "    surface_size: int,\n",
    ") -> typing.Optional[int]:\n",
    "\n",
    "    first_incidence_rank = pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "        hanoi_value, 0\n",
    "    )\n",
    "    max_reservations_provided = get_num_reservations_provided(\n",
    "        hanoi_value=hanoi_value,\n",
    "        surface_size=surface_size,\n",
    "        rank=first_incidence_rank,\n",
    "    )\n",
    "    if reservation_index == 0:\n",
    "        # special case because we implicitly assume\n",
    "        # always at least one reservation index\n",
    "        res = get_surface_rank_capacity(surface_size) - 1\n",
    "        assert res\n",
    "        return res\n",
    "    elif reservation_index >= max_reservations_provided:\n",
    "        return None\n",
    "    else:\n",
    "\n",
    "        def predicate(rank: int) -> bool:\n",
    "            return (\n",
    "                get_num_reservations_provided(\n",
    "                    hanoi_value=hanoi_value,\n",
    "                    surface_size=surface_size,\n",
    "                    rank=rank,\n",
    "                )\n",
    "                <= reservation_index\n",
    "            )\n",
    "\n",
    "        assert not predicate(0)\n",
    "        upper_bound = get_surface_rank_capacity(surface_size) - 1\n",
    "        assert predicate(upper_bound)\n",
    "        res = (\n",
    "            inch.binary_search(\n",
    "                predicate,\n",
    "                first_incidence_rank,\n",
    "                # upper bound prevents assertion errors from out of bounds queries\n",
    "                upper_bound,\n",
    "            )\n",
    "        )\n",
    "        assert res, {\n",
    "            \"first_incidence_rank\": first_incidence_rank,\n",
    "            \"max_reservations_provided\": max_reservations_provided,\n",
    "            \"res\": res,\n",
    "            \"reservation_index\": reservation_index,\n",
    "            \"surface_size\": surface_size,\n",
    "            \"upper_bound\": upper_bound,\n",
    "        }\n",
    "        return res\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_reservation_index_elimination_rank\n",
    "# helper function for test\n",
    "def make_num_reservations_provided_df(surface_size: int) -> pd.DataFrame:\n",
    "    num_generations = min(\n",
    "        2**12,\n",
    "        get_surface_rank_capacity(surface_size) - 1,\n",
    "    )\n",
    "    records = []\n",
    "    max_hanoi_value = pylib.hanoi.get_max_hanoi_value_through_index(\n",
    "        num_generations - 1\n",
    "    )\n",
    "    for hanoi_value in range(max_hanoi_value):\n",
    "        first_incidence_rank = (\n",
    "            pylib.hanoi.get_index_of_hanoi_value_nth_incidence(hanoi_value, 0)\n",
    "        )\n",
    "        for rank in tqdm(range(first_incidence_rank, num_generations)):\n",
    "            num_reservations_provided = get_num_reservations_provided(\n",
    "                hanoi_value=hanoi_value,\n",
    "                surface_size=surface_size,\n",
    "                rank=rank,\n",
    "            )\n",
    "            incidence_count = pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "                hanoi_value,\n",
    "                rank,\n",
    "            )\n",
    "            assert incidence_count\n",
    "            records.append(\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"hanoi value\": hanoi_value,\n",
    "                    \"hanoi incidence\": incidence_count - 1,\n",
    "                    \"num reservations provided\": num_reservations_provided,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_reservation_index_elimination_rank\n",
    "# demo helper function for test\n",
    "nrp_df = make_num_reservations_provided_df(32)\n",
    "\n",
    "display(nrp_df)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=nrp_df,\n",
    "    x=\"rank\",\n",
    "    y=\"num reservations provided\",\n",
    "    hue=\"hanoi value\",\n",
    ")\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_reservation_index_elimination_rank\n",
    "# actual test\n",
    "\n",
    "for surface_size in 16, 32, 64:\n",
    "    nrp_df = make_num_reservations_provided_df(surface_size)\n",
    "\n",
    "    for hanoi_value, hv_df in nrp_df.groupby(\"hanoi value\"):\n",
    "        assert hv_df[\"num reservations provided\"].is_monotonic_decreasing\n",
    "        max_reservations_provided = hv_df[\"num reservations provided\"].max()\n",
    "        expected = None\n",
    "        actual = get_reservation_index_elimination_rank(\n",
    "            hanoi_value=hanoi_value,\n",
    "            reservation_index=max_reservations_provided,\n",
    "            surface_size=surface_size,\n",
    "        )\n",
    "        assert expected == actual, {\n",
    "            \"expected\": expected,\n",
    "            \"actual\": actual,\n",
    "            \"hanoi value\": hanoi_value,\n",
    "            \"reservation index\": max_reservations_provided,\n",
    "            \"surface size\": surface_size,\n",
    "        }\n",
    "        max_covered_rank = hv_df[\"rank\"].max()\n",
    "\n",
    "        for nrp, nrp_df_ in hv_df.groupby(\"num reservations provided\"):\n",
    "            assert nrp\n",
    "            reservation_index = nrp - 1\n",
    "            expected_last = nrp_df_[\"rank\"].max()\n",
    "            actual_last = (\n",
    "                get_reservation_index_elimination_rank(\n",
    "                    hanoi_value=hanoi_value,\n",
    "                    reservation_index=reservation_index,\n",
    "                    surface_size=surface_size,\n",
    "                )\n",
    "                - 1\n",
    "            )\n",
    "            assert actual_last >= 0\n",
    "            if (\n",
    "                expected_last < max_covered_rank\n",
    "            ):  # skip where coverage goes off end of sampled ranks\n",
    "                assert expected_last == actual_last, {\n",
    "                    \"expected last\": expected_last,\n",
    "                    \"actual last\": actual_last,\n",
    "                    \"hanoi value\": hanoi_value,\n",
    "                    \"reservation index\": reservation_index,\n",
    "                    \"surface size\": surface_size,\n",
    "                }\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_candidate_reservation_sizes(\n",
    "    site: int,\n",
    "    rank: int,\n",
    ") -> typing.Iterator[int]:\n",
    "    # this is going BACK in time\n",
    "    naive_reservation_size = get_num_sites_reserved_per_incidence_at_rank(rank)\n",
    "\n",
    "    reservation_size = naive_reservation_size\n",
    "    while reservation_size:\n",
    "        candidate_hanoi_value = site % reservation_size\n",
    "        yield reservation_size\n",
    "        reservation_size //= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_candidate_hanoi_occupants(\n",
    "    site: int,\n",
    "    rank: int,\n",
    ") -> typing.Iterator[int]:\n",
    "    # this is going BACK in time\n",
    "    for candidate_reservation_size in iter_candidate_reservation_sizes(site, rank):\n",
    "        candidate_hanoi_value = site % candidate_reservation_size\n",
    "        yield candidate_hanoi_value\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test iter_candidate_hanoi_occupants\n",
    "for surface_size in 16, 32, 64:\n",
    "    capacity = get_surface_rank_capacity(surface_size)\n",
    "    for rank in it.chain(\n",
    "        range(300),\n",
    "        map(int, np.linspace(0, capacity, num=100, dtype=int)),\n",
    "    ):\n",
    "        {*iter_candidate_hanoi_occupants(0, rank)} == {0}\n",
    "\n",
    "        for site in range(surface_size):\n",
    "            assert hstrat_aux.is_nonincreasing(\n",
    "                iter_candidate_hanoi_occupants(site, rank)\n",
    "            )\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(1, 2)} == {0, 1}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(1, 5559)} == {0, 1}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(6, 5)} == {0, 2}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(5, 5)} == {0, 1}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(7, 5)} == {0, 1, 3}\n",
    "\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(6, 16)} == {0, 2, 6}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(5, 16)} == {0, 1, 5}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(7, 16)} == {0, 1, 3, 7}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(8, 16)} == {0}\n",
    "\n",
    "assert {*iter_candidate_hanoi_occupants(9, 16)} == {0, 1}\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_candidate_reservation_indices(\n",
    "    site: int,\n",
    "    surface_size: int,\n",
    "    rank: int,\n",
    ") -> typing.Iterator[int]:\n",
    "    # this is going BACK in time\n",
    "\n",
    "    for candidate_reservation_size in iter_candidate_reservation_sizes(site, rank):\n",
    "        candidate_reservation_position = site // candidate_reservation_size\n",
    "        candidate_reservation_index = (\n",
    "            pylib.longevity_ordering_descending.get_longevity_index_of_mapped_position(\n",
    "                candidate_reservation_position,\n",
    "                surface_size // candidate_reservation_size,\n",
    "            )\n",
    "        )\n",
    "        yield candidate_reservation_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pylib.log_args_and_result(logger, logging.DEBUG)\n",
    "def calc_reservation_reference_incidence(\n",
    "    hanoi_value: int,\n",
    "    reservation_index: int,\n",
    "    surface_size: int,\n",
    "    focal_rank: int,\n",
    ") -> int:\n",
    "    num_reservations_provided = get_num_reservations_provided(\n",
    "        hanoi_value=hanoi_value,\n",
    "        surface_size=surface_size,\n",
    "        rank=focal_rank,\n",
    "    )\n",
    "    assert num_reservations_provided\n",
    "    assert reservation_index < num_reservations_provided, {\n",
    "        \"hanoi_value\": hanoi_value,\n",
    "        \"reservation_index\": reservation_index,\n",
    "        \"surface_size\": surface_size,\n",
    "        \"focal_rank\": focal_rank,\n",
    "        \"num_reservations_provided\": num_reservations_provided,\n",
    "    }\n",
    "\n",
    "    num_incidences = pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "        hanoi_value,\n",
    "        focal_rank,\n",
    "    )\n",
    "    assert num_incidences\n",
    "    hanoi_incidence = num_incidences - 1\n",
    "\n",
    "    incidence_position = hanoi_incidence % num_reservations_provided\n",
    "    candidate_incidence = hanoi_incidence - incidence_position\n",
    "\n",
    "    if reservation_index > incidence_position:\n",
    "        # should only recurse once?\n",
    "        cadence = pylib.hanoi.get_hanoi_value_index_cadence(hanoi_value)\n",
    "        candidate_rank = pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "            hanoi_value,\n",
    "            candidate_incidence,\n",
    "        )\n",
    "        assert candidate_rank\n",
    "        return calc_reservation_reference_incidence(\n",
    "            hanoi_value,\n",
    "            reservation_index,\n",
    "            surface_size,\n",
    "            candidate_rank - 1,\n",
    "        )\n",
    "    else:\n",
    "        assert candidate_incidence % num_reservations_provided == 0, {\n",
    "            \"candidate_incidence\": candidate_incidence,\n",
    "            \"num_reservations_provided\": num_reservations_provided,\n",
    "        }\n",
    "        return candidate_incidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calc_reservation_reference_rank test\n",
    "# helper function for test\n",
    "def make_reference_incidence_df(surface_size: int, max_generations: int = 2**12) -> pd.DataFrame:\n",
    "    num_generations = min(\n",
    "        max_generations,\n",
    "        get_surface_rank_capacity(surface_size) - 1,\n",
    "    )\n",
    "    records = []\n",
    "    surface_ingest_ranks = [-1] * surface_size\n",
    "    surface_ingest_incidences = [-1] * surface_size\n",
    "    for rank in tqdm(range(num_generations)):\n",
    "        target_rank = get_ingest_site_at_rank(rank, surface_size)\n",
    "        surface_ingest_ranks[target_rank] = rank\n",
    "        surface_ingest_incidences[target_rank] = pylib.hanoi.get_hanoi_value_incidence_at_index(rank)\n",
    "\n",
    "        max_hanoi_value = pylib.hanoi.get_max_hanoi_value_through_index(rank)\n",
    "        for hanoi_value in range(max_hanoi_value):\n",
    "            assert surface_ingest_ranks[hanoi_value] != -1\n",
    "            assert surface_ingest_incidences[hanoi_value] != -1\n",
    "\n",
    "            records.append(\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"hanoi value\": hanoi_value,\n",
    "                    \"num reservations provided\": get_num_reservations_provided(\n",
    "                        hanoi_value=hanoi_value,\n",
    "                        surface_size=surface_size,\n",
    "                        rank=rank,\n",
    "                    ),\n",
    "                    \"reference rank\": surface_ingest_ranks[hanoi_value],\n",
    "                    \"reference incidence\": surface_ingest_incidences[hanoi_value],\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calc_reservation_reference_incidence test\n",
    "# helper function for test\n",
    "\n",
    "rr_df = make_reference_incidence_df(32, max_generations=1000)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=rr_df,\n",
    "    x=\"rank\",\n",
    "    y=\"reference rank\",\n",
    "    hue=\"hanoi value\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "g = sns.FacetGrid(rr_df, col=\"hanoi value\", col_wrap=3, sharey=False)\n",
    "g.map_dataframe(sns.lineplot, x=\"rank\", y=\"reference incidence\")\n",
    "plt.show()\n",
    "\n",
    "display(rr_df)\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration for calc_reservation_reference_incidence\n",
    "rr_df = make_reference_incidence_df(32, max_generations=100)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    fil_df = rr_df[rr_df[\"hanoi value\"] == 0]\n",
    "    print(fil_df[\"reference rank\"].unique())\n",
    "    print(fil_df[\"reference incidence\"].unique())\n",
    "    display(fil_df)\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration for calc_reservation_reference_incidence\n",
    "rr_df = make_reference_incidence_df(32, max_generations=8000)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    fil_df = rr_df[rr_df[\"hanoi value\"] == 4]\n",
    "    print(fil_df[\"reference rank\"].unique())\n",
    "    print(fil_df[\"reference incidence\"].unique())\n",
    "    display(fil_df[\n",
    "        (fil_df[\"rank\"] > 3850)\n",
    "        & (fil_df[\"rank\"] < 3860)\n",
    "    ])\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calc_reservation_reference_rank test\n",
    "# helper function for test\n",
    "def make_dense_reference_incidence_df(surface_size: int, max_generations: int = 2**12) -> pd.DataFrame:\n",
    "    num_generations = min(\n",
    "        max_generations,\n",
    "        get_surface_rank_capacity(surface_size) - 1,\n",
    "    )\n",
    "    surface_ingest_ranks = [-1] * surface_size\n",
    "    surface_ingest_incidences = [-1] * surface_size\n",
    "    surface_hanoi_values = [-1] * surface_size\n",
    "    surface_ingest_reference_incidences = [-1] * surface_size\n",
    "    surface_ingest_reference_ranks = [-1] * surface_size\n",
    "\n",
    "    records = []\n",
    "    for rank in tqdm(range(num_generations)):\n",
    "        ingest_hanoi_value = pylib.hanoi.get_hanoi_value_at_index(rank)\n",
    "        target_rank = get_ingest_site_at_rank(rank, surface_size)\n",
    "        surface_hanoi_values[target_rank] = ingest_hanoi_value\n",
    "        surface_ingest_ranks[target_rank] = rank\n",
    "        surface_ingest_incidences[target_rank] = pylib.hanoi.get_hanoi_value_incidence_at_index(rank)\n",
    "        surface_ingest_reference_ranks[target_rank] = surface_ingest_ranks[\n",
    "            ingest_hanoi_value\n",
    "        ]\n",
    "        surface_ingest_reference_incidences[target_rank] = surface_ingest_incidences[\n",
    "            ingest_hanoi_value\n",
    "        ]\n",
    "\n",
    "        for (\n",
    "            site,\n",
    "            site_hanoi_value,\n",
    "            site_ingest_incidence,\n",
    "            site_ingest_rank,\n",
    "            site_ingest_reference_incidence,\n",
    "            site_ingest_reference_rank,\n",
    "        ) in zip(\n",
    "            it.count(),\n",
    "            surface_hanoi_values,\n",
    "            surface_ingest_incidences,\n",
    "            surface_ingest_ranks,\n",
    "            surface_ingest_reference_incidences,\n",
    "            surface_ingest_reference_ranks,\n",
    "        ):\n",
    "            if site_hanoi_value == -1:\n",
    "                assert site_ingest_incidence == -1\n",
    "                assert site_ingest_rank == -1\n",
    "                assert site_ingest_reference_rank == -1\n",
    "                continue\n",
    "\n",
    "            num_reservations_provided = get_num_reservations_provided(\n",
    "                hanoi_value=site_hanoi_value,\n",
    "                surface_size=surface_size,\n",
    "                rank=rank,\n",
    "            )\n",
    "            num_chunks = pylib.bit_ceil(num_reservations_provided)\n",
    "            chunk_size = surface_size // num_chunks\n",
    "            reservation_index = (\n",
    "                pylib.longevity_ordering_descending.get_longevity_index_of_mapped_position(\n",
    "                    site // chunk_size,\n",
    "                    num_chunks,\n",
    "                )\n",
    "            )\n",
    "            if site % chunk_size != site_hanoi_value or reservation_index >= num_reservations_provided:\n",
    "                continue  # derelict sites, skip\n",
    "\n",
    "            assert (site < chunk_size) == (reservation_index == 0), {\n",
    "                \"site\": site,\n",
    "                \"reservation_index\": reservation_index,\n",
    "            }\n",
    "\n",
    "            data = {\n",
    "                \"rank\": rank,\n",
    "                \"site\": site,\n",
    "                \"hanoi value\": site_hanoi_value,\n",
    "                \"ingest incidence\": site_ingest_incidence,\n",
    "                \"ingest rank\": site_ingest_rank,\n",
    "                \"ingest reference incidence\": site_ingest_reference_incidence,\n",
    "                \"ingest reference rank\": site_ingest_reference_rank,\n",
    "                \"num reservations provided\": num_reservations_provided,\n",
    "                \"reservation index\": reservation_index,\n",
    "                \"chunk size\": chunk_size,\n",
    "                \"num chunks\": num_chunks,\n",
    "            }\n",
    "            records.append(data)\n",
    "\n",
    "            assert reservation_index < num_reservations_provided, data\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calc_reservation_reference_incidence\n",
    "# actual test\n",
    "\n",
    "for surface_size in 16, 32, 64:\n",
    "\n",
    "    reference_incidence_df = make_dense_reference_incidence_df(surface_size)\n",
    "    for index, row in reference_incidence_df.iterrows():\n",
    "        actual = calc_reservation_reference_incidence(\n",
    "            int(row[\"hanoi value\"]),\n",
    "            int(row[\"reservation index\"]),\n",
    "            surface_size,\n",
    "            int(row[\"rank\"]),\n",
    "        )\n",
    "        expected = row[\"ingest reference incidence\"]\n",
    "        if actual != expected:\n",
    "            print(row)\n",
    "        assert actual == expected, {\n",
    "            \"actual\": actual,\n",
    "            \"expected\": expected,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pylib.log_args_and_result(logger, logging.DEBUG)\n",
    "def calc_incidence_of_ingested_hanoi_value(\n",
    "    hanoi_value: int,\n",
    "    reservation_index: int,\n",
    "    surface_size: int,\n",
    "    focal_rank: int,\n",
    "    _is_recurse = False,\n",
    ") -> int:\n",
    "    num_reservations_provided = get_num_reservations_provided(\n",
    "        hanoi_value=hanoi_value,\n",
    "        surface_size=surface_size,\n",
    "        rank=focal_rank,\n",
    "    )\n",
    "    assert num_reservations_provided\n",
    "\n",
    "    assert reservation_index <= num_reservations_provided\n",
    "\n",
    "    focal_count = pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "        hanoi_value,\n",
    "        focal_rank,\n",
    "    )\n",
    "    assert focal_count\n",
    "\n",
    "    focal_incidence = focal_count - 1\n",
    "    # this case (not enough ingests to reach reservation)\n",
    "    # is handled elsewhere before this fn\n",
    "    assert focal_incidence >= reservation_index\n",
    "\n",
    "    # figure out where the modulus lines up at the zero position\n",
    "    reference_incidence = calc_reservation_reference_incidence(\n",
    "        hanoi_value = hanoi_value,\n",
    "        reservation_index = reservation_index,\n",
    "        surface_size = surface_size,\n",
    "        focal_rank = focal_rank,\n",
    "    )\n",
    "    assert reference_incidence >= 0\n",
    "\n",
    "    assert focal_incidence >= reference_incidence  # ? need to handle here?\n",
    "\n",
    "    incidence_duration = focal_incidence - reference_incidence\n",
    "    assert incidence_duration >= reservation_index\n",
    "\n",
    "    logger.debug(\n",
    "        {\n",
    "            \"focal_count\": focal_count,\n",
    "            \"focal_incidence\": focal_incidence,\n",
    "            \"incidence_duration\": incidence_duration,\n",
    "            \"num_reservations_provided\": num_reservations_provided,\n",
    "            \"reference_incidence\": reference_incidence,\n",
    "            \"reservation_index\": reservation_index,\n",
    "            \"surface_size\": surface_size,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    res = reference_incidence + reservation_index\n",
    "    assert res <= focal_incidence, {\n",
    "        \"res\": res,\n",
    "        \"focal_incidence\": focal_incidence,\n",
    "        \"reference incidence\": reference_incidence,\n",
    "        \"reservation index\": reservation_index,\n",
    "    }  # make sure incidence has actually occured\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pylib.log_args_and_result(logger, logging.DEBUG)\n",
    "def calc_rank_of_ingested_hanoi_value(\n",
    "    hanoi_value: int,\n",
    "    reservation_index: int,\n",
    "    surface_size: int,\n",
    "    focal_rank: int,\n",
    ") -> int:\n",
    "    incidence = calc_incidence_of_ingested_hanoi_value(\n",
    "        hanoi_value,\n",
    "        reservation_index,\n",
    "        surface_size,\n",
    "        focal_rank,\n",
    "    )\n",
    "    res = pylib.hanoi.get_index_of_hanoi_value_nth_incidence(\n",
    "        hanoi_value,\n",
    "        incidence,\n",
    "    )\n",
    "    assert res <= focal_rank, {\n",
    "        \"hanoi_value\" : hanoi_value,\n",
    "        \"incidence\" : incidence,\n",
    "        \"focal_rank\" : focal_rank,\n",
    "        \"res\": res,\n",
    "        \"reservation_index\" : reservation_index,\n",
    "        \"surface_size\" : surface_size,\n",
    "    }\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3b: Define `get_ingest_rank_at_site`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingest_rank_at_site(\n",
    "    site: int, surface_size: int, num_ingests: int\n",
    ") -> int:\n",
    "\n",
    "    if num_ingests == 0:\n",
    "        return 0\n",
    "\n",
    "    rank = num_ingests - 1\n",
    "\n",
    "    for candidate_hanoi_value, candidate_reservation_index in zip(\n",
    "        iter_candidate_hanoi_occupants(site, rank),\n",
    "        iter_candidate_reservation_indices(site, surface_size, rank),\n",
    "    ):\n",
    "        logger.debug(f\"{candidate_hanoi_value=}\")\n",
    "        logger.debug(f\"{candidate_reservation_index=}\")\n",
    "        deadline_rank = get_reservation_index_elimination_rank(\n",
    "            candidate_hanoi_value,\n",
    "            candidate_reservation_index,\n",
    "            surface_size,\n",
    "        )\n",
    "        logger.debug(f\"{deadline_rank=}\")\n",
    "        if deadline_rank is None:\n",
    "            continue  # could this be a break?\n",
    "\n",
    "        assert deadline_rank, {\n",
    "            \"candidate_hanoi_value\": candidate_hanoi_value,\n",
    "            \"candidate_reservation_index\": candidate_reservation_index,\n",
    "            \"rank\": rank,\n",
    "            \"site\": site,\n",
    "            \"surface_size\": surface_size,\n",
    "        }\n",
    "\n",
    "        focal_rank = min(rank, deadline_rank - 1)\n",
    "        assert focal_rank <= rank\n",
    "        logger.debug(f\"{focal_rank=}\")\n",
    "\n",
    "        hanoi_count = pylib.hanoi.get_incidence_count_of_hanoi_value_through_index(\n",
    "            candidate_hanoi_value,\n",
    "            focal_rank,\n",
    "        )\n",
    "        if hanoi_count > candidate_reservation_index:\n",
    "            res = calc_rank_of_ingested_hanoi_value(\n",
    "                candidate_hanoi_value,\n",
    "                candidate_reservation_index,\n",
    "                surface_size,\n",
    "                focal_rank,\n",
    "            )\n",
    "            assert res <= rank, {\n",
    "                \"candidate_hanoi_value\": candidate_hanoi_value,\n",
    "                \"candidate_reservation_index\": candidate_reservation_index,\n",
    "                \"deadline_rank\": deadline_rank,\n",
    "                \"focal_rank\": focal_rank,\n",
    "                \"hanoi_count\": hanoi_count,\n",
    "                \"rank\": rank,\n",
    "                \"res\": res,\n",
    "                \"site\": site,\n",
    "                \"surface_size\": surface_size,\n",
    "            }\n",
    "            return res\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Evaluate `get_ingest_rank_at_site`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4a: Unit Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_ingest_rank_at_site\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(0, 16, num_ingests) for num_ingests in range(22)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     0,  # 1,  # 8,  # 1,\n",
    "#     0,  # 8,  # 8,  # 0,\n",
    "#     0,  # 2,  # 4,  # 2,\n",
    "#     0,  # 4,  # 4,  # 0,\n",
    "#     0,  # 9,  # 4,  # 1,\n",
    "#     0,  # 12, # 4,  # 0,\n",
    "#     0,  # 3,  # 4,  # 3,\n",
    "#     8,  # 0,  # 4,  # 0,\n",
    "#     8,  # 5,  # 4,  # 1,\n",
    "#     8,  # 8,  # 4,  # 0,\n",
    "#     8,  # 10, # 4,  # 2,\n",
    "#     8,  # 4,  # 4,  # 0,\n",
    "#     8,  # 13, # 4,  # 1,\n",
    "#     8,  # 12, # 4,  # 0,\n",
    "#     8,  # 4,  # 2,  # 4,\n",
    "#     16, # 0,  # 2,  # 0,\n",
    "#     16, # 1,  # 2,  # 1,\n",
    "#     16, # 8,  # 2,  # 0,\n",
    "#     16, # 6,  # 2,  # 2,\n",
    "#     20, # 0,  # 2,  # 0,\n",
    "# ]\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(1, 16, num_ingests) for num_ingests in range(22)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     1,  # 1,  # 8,  # 1,\n",
    "#     1,  # 8,  # 8,  # 0,\n",
    "#     1,  # 2,  # 4,  # 2,\n",
    "#     1,  # 4,  # 4,  # 0,\n",
    "#     1,  # 9,  # 4,  # 1,\n",
    "#     1,  # 12, # 4,  # 0,\n",
    "#     1,  # 3,  # 4,  # 3,\n",
    "#     1,  # 0,  # 4,  # 0,\n",
    "#     1,  # 5,  # 4,  # 1,\n",
    "#     1,  # 8,  # 4,  # 0,\n",
    "#     1,  # 10, # 4,  # 2,\n",
    "#     1,  # 4,  # 4,  # 0,\n",
    "#     1,  # 13, # 4,  # 1,\n",
    "#     1,  # 12, # 4,  # 0,\n",
    "#     1,  # 4,  # 2,  # 4,\n",
    "#     1,  # 0,  # 2,  # 0,\n",
    "#     17, # 1,  # 2,  # 1,\n",
    "#     17, # 8,  # 2,  # 0,\n",
    "#     17, # 6,  # 2,  # 2,\n",
    "#     17, # 0,  # 2,  # 0,\n",
    "# ]\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(2, 16, num_ingests) for num_ingests in range(22)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     0,  # 1,  # 8,  # 1,\n",
    "#     0,  # 8,  # 8,  # 0,\n",
    "#     3,  # 2,  # 4,  # 2,\n",
    "#     3,  # 4,  # 4,  # 0,\n",
    "#     3,  # 9,  # 4,  # 1,\n",
    "#     3,  # 12, # 4,  # 0,\n",
    "#     3,  # 3,  # 4,  # 3,\n",
    "#     3,  # 0,  # 4,  # 0,\n",
    "#     3,  # 5,  # 4,  # 1,\n",
    "#     3,  # 8,  # 4,  # 0,\n",
    "#     3,  # 10, # 4,  # 2,\n",
    "#     3,  # 4,  # 4,  # 0,\n",
    "#     3,  # 13, # 4,  # 1,\n",
    "#     3,  # 12, # 4,  # 0,\n",
    "#     3,  # 4,  # 2,  # 4,\n",
    "#     3,  # 0,  # 2,  # 0,\n",
    "#     3,  # 1,  # 2,  # 1,\n",
    "#     3,  # 8,  # 2,  # 0,\n",
    "#     3,  # 6,  # 2,  # 2,\n",
    "#     3,  # 0,  # 2,  # 0,\n",
    "# ]\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(15, 16, num_ingests)\n",
    "#     for num_ingests in range(22)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     0,  # 1,  # 8,  # 1,\n",
    "#     0,  # 8,  # 8,  # 0,\n",
    "#     0,  # 2,  # 4,  # 2,\n",
    "#     0,  # 4,  # 4,  # 0,\n",
    "#     0,  # 9,  # 4,  # 1,\n",
    "#     0,  # 12, # 4,  # 0,\n",
    "#     0,  # 3,  # 4,  # 3,\n",
    "#     0,  # 0,  # 4,  # 0,\n",
    "#     0,  # 5,  # 4,  # 1,\n",
    "#     0,  # 8,  # 4,  # 0,\n",
    "#     0,  # 10, # 4,  # 2,\n",
    "#     0,  # 4,  # 4,  # 0,\n",
    "#     0,  # 13, # 4,  # 1,\n",
    "#     0,  # 12, # 4,  # 0,\n",
    "#     0,  # 4,  # 2,  # 4,\n",
    "#     0,  # 0,  # 2,  # 0,\n",
    "#     0,  # 1,  # 2,  # 1,\n",
    "#     0,  # 8,  # 2,  # 0,\n",
    "#     0,  # 6,  # 2,  # 2,\n",
    "#     0,  # 0,  # 2,  # 0,\n",
    "# ]\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(8, 16, num_ingests) for num_ingests in range(22)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     0,  # 1,  # 8,  # 1,\n",
    "#     2,  # 8,  # 8,  # 0,\n",
    "#     2,  # 2,  # 4,  # 2,\n",
    "#     2,  # 4,  # 4,  # 0,\n",
    "#     2,  # 9,  # 4,  # 1,\n",
    "#     2,  # 12, # 4,  # 0,\n",
    "#     2,  # 3,  # 4,  # 3,\n",
    "#     2,  # 0,  # 4,  # 0,\n",
    "#     2,  # 5,  # 4,  # 1,\n",
    "#     10, # 8,  # 4,  # 0,\n",
    "#     10, # 10, # 4,  # 2,\n",
    "#     10, # 4,  # 4,  # 0,\n",
    "#     10, # 13, # 4,  # 1,\n",
    "#     10, # 12, # 4,  # 0,\n",
    "#     10, # 4,  # 2,  # 4,\n",
    "#     10, # 0,  # 2,  # 0,\n",
    "#     10, # 1,  # 2,  # 1,\n",
    "#     18, # 8,  # 2,  # 0,\n",
    "#     18, # 6,  # 2,  # 2,\n",
    "#     18, # 0,  # 2,  # 0,\n",
    "# ]\n",
    "# assert [\n",
    "#     get_ingest_rank_at_site(9, 16, num_ingests) for num_ingests in range(23)\n",
    "# ] == [\n",
    "#         # ingest site\n",
    "#         #     # num_reservations\n",
    "#         #     #     # hanoi sequence (0-based):\n",
    "#     0,  # ~~~~ n/a ~~~~\n",
    "#     0,  # 0,  # 16, # 0,\n",
    "#     0,  # 1,  # 8,  # 1,\n",
    "#     0,  # 8,  # 8,  # 0,\n",
    "#     0,  # 2,  # 4,  # 2,\n",
    "#     0,  # 4,  # 4,  # 0,\n",
    "#     5,  # 9,  # 4,  # 1,\n",
    "#     5,  # 12, # 4,  # 0,\n",
    "#     5,  # 3,  # 4,  # 3,\n",
    "#     5,  # 0,  # 4,  # 0,\n",
    "#     5,  # 5,  # 4,  # 1,\n",
    "#     5,  # 8,  # 4,  # 0,\n",
    "#     5,  # 10, # 4,  # 2,\n",
    "#     5,  # 4,  # 4,  # 0,\n",
    "#     5,  # 13, # 4,  # 1,\n",
    "#     5,  # 12, # 4,  # 0,\n",
    "#     5,  # 4,  # 2,  # 4,\n",
    "#     5,  # 0,  # 2,  # 0,\n",
    "#     5,  # 1,  # 2,  # 1,\n",
    "#     5,  # 8,  # 2,  # 0,\n",
    "#     5,  # 6,  # 2,  # 2,\n",
    "#     5,  # 0,  # 2,  # 0,\n",
    "#     21, # 9,  # 2,  # 1,\n",
    "# ]\n",
    "\n",
    "pylib.jupyter_hide_toggle(hide=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4b: Integration Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for surface_size_exp in range(2, 12): <--- works, but slow\n",
    "for surface_size_exp in range(2, 8):\n",
    "    logger.setLevel(logging.WARNING)\n",
    "    surface_size = 2**surface_size_exp\n",
    "    num_generations = min(\n",
    "#         2**18, <--- works, but slow\n",
    "        2**(20 - surface_size_exp),\n",
    "        get_surface_rank_capacity(surface_size) - 1,\n",
    "    )\n",
    "    print(f\"evaluating surface size {surface_size} for {num_generations} generations\")\n",
    "\n",
    "    surface_ingest_ranks = [0] * surface_size\n",
    "    for rank in tqdm(range(num_generations)):\n",
    "        target_site = get_ingest_site_at_rank(rank, surface_size)\n",
    "#         print(\n",
    "#             \"rank\", rank,\n",
    "#             \"hanoi\", pylib.hanoi.get_hanoi_value_at_index(rank),\n",
    "#             \"target_site\", target_site\n",
    "#         )\n",
    "        surface_ingest_ranks[target_site] = rank\n",
    "\n",
    "        for site, actual_ingest_rank in enumerate(surface_ingest_ranks):\n",
    "\n",
    "            try:\n",
    "                calculated_ingest_rank = get_ingest_rank_at_site(\n",
    "                    site,\n",
    "                    surface_size,\n",
    "                    rank + 1,\n",
    "                )\n",
    "            except AssertionError as e:\n",
    "                logger.warning(f\"AssertionError {e}\")\n",
    "                logger.warning({\n",
    "                    \"actual_ingest_rank\": actual_ingest_rank,\n",
    "                    \"rank\": rank,\n",
    "                    \"site\": site,\n",
    "                })\n",
    "                calculated_ingest_rank = None\n",
    "\n",
    "            if calculated_ingest_rank != actual_ingest_rank:\n",
    "\n",
    "                logger.setLevel(logging.DEBUG)\n",
    "                get_ingest_rank_at_site(\n",
    "                    site=site,\n",
    "                    surface_size=surface_size,\n",
    "                    num_ingests=rank + 1,\n",
    "                )\n",
    "                logger.setLevel(logging.WARNING)\n",
    "\n",
    "                assert False, {\n",
    "                    \"actual ingest rank\": actual_ingest_rank,\n",
    "                    \"calculated ingest rank\": calculated_ingest_rank,\n",
    "                    \"hanoi value\": pylib.hanoi.get_hanoi_value_at_index(rank),\n",
    "                    \"num ingests\": rank + 1,\n",
    "                    \"rank\": rank,\n",
    "                    \"site\": site,\n",
    "                }\n",
    "\n",
    "pylib.jupyter_hide_toggle()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
