\section{Preliminaries, Notations, and Terminology} \label{sec:notation}

The core function of proposed algorithms is to dynamically filter out a bounded-size subset of incoming data that, according to a desired \textbf{coverage criterion}, manages the structure of gaps in history created by discarding items.
Incoming data is assumed to arrive on a rolling basis, as a \textbf{data stream} comprised of sequential \textbf{data items} $v_i$.
We assume the data stream to be ephemeral (i.e., ``read once''), and refer to the act of reading an item from the data stream as \textbf{ingesting} it.
As mentioned above, we term this scenario the \textbf{data stream curation problem}.

We consider data items according only to their logical sequence position.
We do not consider data items' actual semantic values or real-time arrival.
We assume data items to be fixed size and thus interchangeable in memory buffer slots.

The remainder of this section will proceed to overview key notations used throughout this work, summarized in Table \ref{tab:notation}.

\input{tab/notation.tex}

\subsection{Buffer Storage $\colorS$}
\label{sec:notation-buffer}

We assume a fixed \textit{number of available buffer sites}, sufficient to store $\colorS$ data items.%
\footnote{%
In associated materials, the fixed-size buffer used to store curated data items is referred to as a ``surface.''
Space-efficient solutions for the stream curation problem under extensible memory capacity have been considered in other work \citep{moreno2024algorithms}.%
}
Proposed algorithms require buffer size $\colorS$ as an even power of two, larger than 4. That is, $\colorS = 2^{\colors}$ for some integer $\colors \in \mathbb{N}_{\geq 2}$.
On occasion, it will become necessary to refer to a specific buffer position $\colork$.
We will take a zero-indexing convention, so $\colork \in [0\twodots\colorS)$.

We consider only one update operation on the buffer: storage of an ingested data item at a buffer site $\colork$.
Under this scheme, control of what data is retained and for how long occurs solely as a consequence of \textit{ingestion site selection} --- picking where (and if) to store incoming data items.
Let $\colorK(\colorT) \in [0\twodots\colorS)\cup\{\nullval\}$ denote the site selection operation to place data item $\colorT$ --- with $\nullval$ denoting a data item dropped without storing.%
\footnote{%
A more exacting notation would reflect that site selection depends on buffer size (i.e., as $\colorK_{\colorS}(\colorT)$), but we omit this in our notation for brevity.
}
A schematic of site selection is provided in Figure \ref{fig:surface-site-ingest}.

As a space-saving optimization, we store only the data items themselves in buffer space --- no metadata (e.g., ingestion time) or data structure components (e.g., indices or pointers) are stored.
This optimization is critical, in particular, when data items are small --- such as single bits or single bytes \citep{moreno2022hereditary}.
Without metadata, however, identifying stored data items requires capability to deduce ingest time solely from buffer position $\colork$.
We denote \textit{site lookup} this operation as $\colorL(\colorT)$, yielding the data item ingest times $\colorTbar_{\colork=0}, \colorTbar_{\colork=1}, \;\;\ldots, \colorTbar_{\colork=\colorS-1}$.
Note that if no data item has yet been stored at a site (i.e., when first filling the buffer $\colorT < \colorS$), $\colorL(\colorT)$ may include $\nullval$ values.%
\footnote{%
Although omitted for brevity, it is the case that lookup depends on buffer size (i.e., as $\colorL_{\colorS}(\colorT)$).
}
Figure \ref{fig:ingest-rank-calculation} visualizes the relationship of \textit{site selection} and \textit{site lookup} operations.

\subsection{Logical Time $\colorT$ and Item Ingest Time $\colorTbar$}
\label{sec:notation-time}

We will refer to each data item's stream sequence index as its \textbf{ingest time} $\colorTbar$ and the number of items ingested as the \textbf{current logical time} $\colorT$.
In other contexts, a data item's ingest time $\colorTbar$ might be referred to as its ``sequence position'' within the data stream.
However, we avoid that terminology to prevent confusion of sequence position with buffer position $\colork$.

We use a zero-indexing convention.
Logical time begins at $\colorT=0$, when no data items have yet been ingested.
The first element of the data stream $v_0$ is assigned ingestion time $\colorTbar=0$.
After the first item $v_0$ is ingested, logical time advances to $\colorT=1$.
We assume $\colorT$ to be known at every point, which can be accomplished trivially in practice with a simple counter.
Because we are only concerned with the sequence order of data items (and not their actual data values), we will shorthand $\colorTbar$ as referring to $v_{\colorTbar}$ (i.e., the data item ingested at that time).

\subsection{Gap Size $\colorg$}
\label{sec:notation-gapsize}

% Be reminded that \textit{coverage criteria} for retained data items considered here operate solely in terms of items' time indices $\colorTbar$.
We define coverage criteria in terms of \textbf{gap sizes} in the retained record.
Formally, we define gap size as a count of consecutive data items that have been discarded or overwritten.
Let $\colorB_{\colorT}$ denote data items retained in buffer at time $\colorT$ (including $v_{\colorT}$) and $\colorBnot_{\colorT}$ refer to data items discarded (i.e., overwritten) up to that point.
Gap size for record index $\colorTbar \in [0 \twodots \colorT)$ at time $\colorT$ follows as
\begin{align}
\colorG_{\colorT}(\colorTbar)
&\coloneq
\max
\{
  i + j
  \text{ for }
  i,\;\; j \in \mathbb{N}
  :
  [\colorTbar-i \twodots \colorTbar+j) \subseteq \colorBnot_{\colorT}
\}.
\label{eqn:gap-size-defn}
\end{align}
Note that if $\colorTbar \in \colorB_{\colorT}$, then $\colorG_{\colorT}(\colorTbar) = 0$.

\subsection{Time Hanoi Value $\colorh$}
\label{sec:notation-hanoi}

Proposed algorithms make heavy use of OEIS integer sequence A007814 \citep{oeis}, formulated as
\begin{align}
\colorH(\colorT)
\coloneq
\max \{ n \in \mathbb{N} : (\colorT + 1) \bmod 2^n = 0 \}.
\label{eqn:hanoi-defn}
\end{align}
We refer to $\colorH(\colorT) = \colorh$ as the ``\textbf{hanoi value}'' (``\textbf{\hv{}}'') of $\colorT$, in reference to parallels with the famous ``Tower of Hanoi'' puzzle \citep{lucas1889jeux}.

Terms of this sequence correspond to the number of trailing zeros in the binary representation of $\colorT + 1$.%
\footnote{%
As such, in implementation, $\colorH(\colorT)$ can be calculated in fast $\mathcal{O}(1)$ using bit-level operations --- e.g., in Python \texttt{($\sim$T \& T-1).bit\_length()} \citep{oeis}.
}
The first terms are $0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 3,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 4,\allowbreak 0,\allowbreak \;\;\ldots \;\;$.
We continue our zero-indexing convention, so $\colorH(0) = 0$, $\colorH(1) = 1$, $\colorH(2) = 0$, etc.

Some intuition for the structure of the Hanoi sequence will benefit the reader.
As depicted in Figure \ref{fig:hanoi-intuition}, the hanoi sequence exhibits recursively-nested fractal structure.
Element 0 appears every 2nd entry, element 1 appears every 4th entry, and in the general case element $\colorh$ appears every $2^{\colorh+1}$th entry.
So, a hanoi value $\colorh$ appears twice as often as value $\colorh + 1$.
When hanoi value $\colorh$ appears for the first time, the value $\colorh - 1$ has appeared exactly once.
So, we have seen precisely one instance of $\colorh$ and also precisely one instance of $\colorh - 1$.
At this point, the value $\colorh - 2$ has appeared exactly twice and, in general, the value $\colorh - n$ has appeared $2^{n - 1}$ times.

DStream algorithms use the \hv{} of data items' ingestion times $\colorH(\colorT)$ as the basis to prioritize items for retention.
Figure \ref{fig:hanoi-intuition} provides intuition for how this core aspect of structure manifests in proposed \textit{steady}, \textit{stretched}, and \textit{tilted} algorithms.

\input{fig/hanoi-intuition.tex}

\subsection{Time Epoch $\colort$}
\label{sec:notation-epoch}

Owing to our algorithms' incorporation of \hv{}-based abstractions, it is useful to track a measure related to the binary magnitude of elapsed time $\colorT$ (i.e., $\sim \log_2(\colorT)$).
We call this measure the \textbf{epoch} $\colort$ of time $\colorT$,
\begin{equation}
\colort
\coloneq
\begin{cases}
\left\lfloor \log_2(\colorT) \right\rfloor - \colors + 1 & \text{if $\colorT \geq \colorS$} \\
0 & \text{otherwise.}
\end{cases}
\label{eqn:epoch-defn}
\end{equation}

Under this definition, epochs begin exactly at even powers of two (e.g., $\colorT = 16$) for $\colorT \geq \colorS$.
Correction is applied to begin epoch $\colort=1$ at $\colorT = \colorS$.

\subsection{Site Reservations $\colorHcal_{\colort}(\colork)$}
\label{sec:notation-reservation}

Algorithm design is structured around ``reserving'' (setting aside) buffer sites $\colork \in [0 \twodots \colorS)$ to host data items whose time index $\colorTbar$ has a specific \hv{}, $\{\colorTbar : \colorH(\colorTbar) = \colorh \}$, on an epoch-to-epoch-basis.
Denote site $\colork$'s \textbf{hanoi value reservation} during epoch $\colort$ as $\colorHcal_{\colort}(\colork)$.%
\footnote{
A careful reader may wonder if the notation for site $\colork$'s hanoi value reservation $\colorHcal_{\colort}(\colork)$ should also be qualified by overall buffer size $\colorS$ as $\colorHcal_{\colort,\colorS}(\colork)$, in addition to current epoch $\colort$.
Although omitted from our notation for brevity, this is indeed the case.
}
Note that a data item $\colorTbar \not\in \colortsetofT$ may occupy site $\colork$ during epoch $\colort$ with $\colorHcal_{\colort}(\colork) \neq \colorH(\colorTbar)$, having been held over from the previous epoch $\colort - 1$ before being overwriten with an instance of \hv{} $\colorh = \colorHcal_{\colort}(\colork)$ during the current epoch $\colort$.

A substantial fraction of implementation for presented algorithms relates to how hanoi value reservations $\colorHcal_{\colort}$ are arranged over buffer space $\colork \in [0\twodots\colorS)$ as epochs $\colort$ elapse.
Each algorithm organizes buffer space into contiguous \textbf{reservation segments}.
Within a single reservation segment, all hanoi value reservations are distinct.
That is, no two sites share the same reserved hanoi value.
Reservation segments are themselves further organized into \textbf{segment bunches}.
All segments within a bunch are the same length and have the same left-to-right hanoi value reservation layout.
However, unlike sites in a segment, segments in a bunch may not be laid out contiguously.
Reservation segments in a bunch are contiguous in buffer space under the steady algorithm, but are not under the stretched and tilted algorithms.

Beyond the commonalities above, the precise makeup and layout of segments and segment bunches differs between the steady algorithm versus the stretched and tilted algorithms.
(The latter two algorithms share large commonalities.)
Figures \ref{fig:hsurf-steady-intuition-heatmap} and \ref{fig:hsurf-stretched-intuition-reservations} sketch the makeup of hanoi value reservations, reservation segments, and segment bunches in buffer space over time for the steady algorithm and stretched/tilted algorithms, respectively.
Further details are covered separately for each algorithm in Sections \cref{sec:steady,sec:stretched,sec:tilted}.

\subsection{Time Meta-epoch $\colortau$}
\label{sec:notation-metaepoch}

In the case of the \textit{stretched} and \textit{tilted} algorithms, it becomes useful to group sequential epochs $\colort$ together as \textbf{meta-epochs} $\colortau$.
We define $\colortau=0$ as corresponding to epoch $\colort=0$.
Meta-epoch $\colortau=1$ therefore begins at epoch $\colort = 1$.
As later motivated in Lemma \ref{thm:stretched-meta-epoch}, we define meta-epochs $\colortau\geq1$ as lasting $2^{\colortau} - 1$ epochs.
Under this definition, we have $\colortau\geq1$ as beginning at epoch
\begin{align}
\min(\colort \in \colortausetoft)
&= 1 + \sum_{i=1}^{\colortau - 1} (2^{i} - 1) \nonumber \\
&= 2^{\colortau} - \colortau.
\label{eqn:meta-epoch-defn}
\end{align}
For epoch $\colort > 0$, we can thus calculate the current meta-epoch $\colortau$ exactly as
\begin{align*}
\colortau
=
\begin{cases}
\left\lfloor \log_2(\colort) \right\rfloor + 1 & \text{if } \colort = 2^{\left\lfloor \log_2(\colort) \right\rfloor} - \left\lfloor \log_2(\colort) \right\rfloor \\
\left\lfloor \log_2(\colort) \right\rfloor & \text{otherwise.}
\end{cases}
\end{align*}

\subsection{Restrictions on Logical Time $\colorT$, Epoch $\colort$, and Meta-epoch $\colortau$}

Ideally, data stream curation would support indefinite ingestions, $\colorT \in \mathbb{N}$.
Our proposed \textit{steady curation} algorithm, introduced below, operates in this fashion.
However, our proposed \textit{stretched} and \textit{tilted curation} algorithms accept only $2^{\colorS} - 2$ ingestions.
We expect this capacity to suffice for many applications using even moderately sized buffers.
For instance, a buffer with space for 64 data items suffices to ingest items continuously at 5GHz for over 100 years.
As such, we leave behavior for stretched and tilted curation past $2^{\colorS} - 2$ ingests to future work.

For convenience in exposition, note that we formally define and characterize the stretched and tilted algorithms only for $\colorT \in [0 \twodots 2^{\colorS - 1})$.
However, in practice, extension to $\colorT \in [0 \twodots 2^{\colorS} - 1)$ that respects established guarantees on curation quality is straightforward.
All algorithm psuedocode and reference implementations support this extended domain.

Restricting logical time $\colorT < 2^{\colorS - 1}$ bounds time epoch $\colort$ below
\begin{align*}
\colort &\leq \left\lfloor\log_2(2^{\colorS - 1} - 1)\right\rfloor - \colors + 1
\leq \colorS - \colors - 1
\end{align*}
assuming $\colorS \geq 4$.
The $\colorS - \colors$ relation can be understood as arising due to delay of epoch $\colort=1$ to time $\colorT = \colorS = 2^{\colors}$.
Supplementary Lemma \ref{thm:meta-epoch-bound} establishes the following upper bound on time meta-epoch $\colortau$,
\begin{align*}
\colortau
&\leq
\min\Big(
  \log_2(\colort + \colors),\;\;
  \log_2(\colort) + 1
\Big)
\text{ for } \colort \in [1 \twodots \colorS - \colors).
\end{align*}
Taking $\colort = \colorS - \colors - 1$, we can also bound $\colortau$ over the stretched and tilted algorithms' domains as $\colortau < \colors$.

\subsection{Miscellania}

Algorithm listings refer to a handful of utility helper functions (e.g., \textsc{BitCount}, \textsc{BitLength}, etc.).
Refer to Supplementary Section \ref{sec:pseudocode} for full definitions of these.

Let the binary floor of a value $x$ be denoted $\left\lfloor x \right\rfloor_\mathrm{bin} = 2^{\left\lfloor \log_2 x \right\rfloor}$.
For binary ceiling, let $\left\lceil x \right\rceil_\mathrm{bin} = 2^{\left\lceil \log_2 x \right\rceil}$.
In both cases, we correct $\left\lfloor x \right\rfloor_\mathrm{bin} = \left\lceil x \right\rceil_\mathrm{bin} = 0$.
As a final piece of minutiae, take $\{2^{\mathbb{N}}\}$ as shorthand for $\{2^n : n \in \mathbb{N} \}$.
