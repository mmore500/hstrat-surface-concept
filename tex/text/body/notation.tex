\section{Preliminaries, Notations, and Terminology} \label{sec:notation}

The core function of proposed algorithms is to dynamically filter out a bounded-size subset of incoming data that, according to a desired \textbf{coverage criterion}, minimizes \textbf{time gaps} between retained data items.
Incoming data is assumed to arrive on a rolling basis, as a \textbf{data stream} comprised of sequential \textbf{data items} $v_i$.
We assume the data stream to be ephemeral (i.e., ``read once''), and refer to the act of reading an item from the data stream as \textbf{ingesting} it.
As mentioned above, we term this scenario the \textbf{data stream curation problem}.

As defined, the objective of stream curation considers data items according only to their \textit{temporal context} (i.e., sequence position), and not actual contained values.
We assume data item values to be fixed size, so as to fit interchangeably in memory buffer slots, but do not consider or discuss semantic values data items actually contain further.
For present discussion, we assume data items to be fixed-size and do not consider the actual values of the data items further.

\subsection{Buffer Storage $\colorS$}
\label{sec:notation-buffer}

We assume a fixed \textit{number of available buffer sites}, sufficient to store $\colorS$ data items.%
\footnote{%
In associated materials, the fixed-size buffer used to store curated data items is referred to as a ``surface.''
Space-efficient solutions for the stream curation problem under extensible memory capacity have been considered in other work \citep{moreno2024algorithms}.%
}
Proposed algorithms require minimal capacity $\colorS\geq4$ and for buffer size to be an even power of two, $\colorS = 2^{\colors}$ for some integer $\colors$.
On occasion, it will become necessary to refer to a specific buffer position $\colork$.
We will take a zero-indexing convention, so $0 \leq \colork < \colorS$.

We consider only one update operation on the buffer: storage of an ingested data item at a buffer site $\colork$.
As a \textit{simplifying limitation}, algorithms do not move, swap, or read already-stored data --- and the only way to discard a stored data item is by overwriting it.
Under this scheme, control of what data is retained and for how long occurs solely as a consequence of \textit{ingestion site selection} --- picking where (and if) to store incoming data items.
In our discussion, let $\colorK(\colorT) \in \cup(\colork \in \colorS, \nullval)$ denote the site selection operation to place data item $\colorTbar$ --- with $\nullval$ denoting a data item dropped without storing.
This site selection operation, schematized in Figure \ref{fig:surface-site-ingest}), takes primary focus herein.

As a space-saving optimization, we store only the data items themselves in buffer space --- no metadata (e.g., ingestion time) or data structure components (e.g., indices or pointers) are stored.
This optimization is critical, in particular, when data items are small --- such as single bits or single bytes \citep{moreno2022hereditary}.
Note, though, that, without metadata, identifying stored data items requires capability to deduce ingestion time solely from buffer position $\colork$.
Figure \ref{fig:ingest-rank-calculation} depicts an example \textit{ingested-time calculation} operation for data retrieval.

\subsection{Time $\colorT$}
\label{sec:notation-time}

We will refer to each data item's stream sequence index as its \textbf{ingestion time} $\colorTbar$ and the most recent ingestion time as the \textbf{current time} $\colorT$.
In referring to time, we will also take a zero-indexing convention, so that the first element of the data stream has ingestion time $\colorTbar=0$.
We assume $\colorT$ to be known for each data ingestion, which is simple to accomplish in practice by simply incrementing a counter each time a data item is ingested.
Because we are only concerned with the sequence order of data items, and not the values of data items themselves, we will interchangeably shorthand $\colorTbar$ as referring to $v_{\colorTbar}$ (the data item ingested at that time).

In principle, data stream curation would support indefinite ingestions, $\colorT \in 0, 1, \ldots \,$.
Our proposed \textit{steady curation} algorithm, introduced below, operates in this fashion.
However, our proposed \textit{stretched} and \textit{tilted curation} algorithms accept only $2^{\colorS}$ ingestions, $\colorT \in 0, 1, \ldots, 2^{\colorS} - 1$.
We expect this capacity to suffice for many applications using even moderately sized buffers.
For instance, a 64-site buffer suffices to ingest items continuously at 5GHz for over 100 years.
As such, we leave behavior for stretched and tilted curation past $2^{\colorS}$ ingests to future work.

\subsection{Gap Size $\colorg$}
\label{sec:notation-gapsize}

Be reminded that \textit{coverage criteria} for retained data items considered here operate solely in terms of items' time indices $\colorTbar$ --- not their data values.
We define coverage criteria in terms of \textbf{gap sizes} in the retained record.
Formally, we define gap size as a count of consecutive data items discarded (i.e., overwritten).
Let $\colorB_{\colorT}$ denote data items retained in buffer at time $\colorT$ (including $v_{\colorT}$) and $\colorBnot_{\colorT}$ refer to data items discarded (i.e., overwritten) up to that point.
So established, gap size at record index $\colorTbar \in \{0,1,\,\ldots,\colorT\}$ follows as
\begin{align*}
\colorG_{\colorT}(\colorTbar) \coloneq \left| \{\colorTbar - m, \,\ldots, \colorTbar, \,\ldots, \colorTbar+n\} \in \colorBnot_{\colorT} \right|_\mathrm{max}.
\end{align*}
Note that if $\colorTbar \in \colorB_{\colorT}$, then $\colorG_{\colorT}(\colorTbar) = 0$.

\subsection{Coverage Criteria}
\label{sec:notation-coverage}

Algorithms cover three main coverage criteria:
\begin{enumerate}
\item \textbf{steady criterion}: seeks to maintain data items \textit{evenly covering} elapsed history (Section \ref{sec:steady}),
\item \textbf{stretched criterion}: favors \textit{older} data items proportionally to their time index $\colorTbar$ (Section \ref{sec:stretched}), and
\item \textbf{tilted criteiron}: favors \textit{newer} items proportionally to their time index recency $\colorT - \colorTbar$ (Section \ref{sec:tilted}).
\end{enumerate}
Figure \ref{fig:criteria-intuition} compares example ideal retention distributions under each criterion.
Formal definitions are provided in each criterion's corresponding section.

\subsection{Time Hanoi Value $\colorh$}
\label{sec:notation-hanoi}

\input{fig/hanoi-intuition.tex}

As shown in Figure \ref{fig:hanoi-intuition} --- and discussed in greater detail later on --- it happens that the structure of proposed algorithms relies heavily on abstractions based around data items' ingestion time $\colorTbar$.
One foundational abstraction is the corresponding value in the ``ruler'' integer sequence $\colorH(\colorTbar) \coloneq \max \{ n \in \mathbb{Z}_{\geq0} : (\colorTbar + 1) \bmod 2^n = 0 \}$.
Note that terms of this sequence $0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 3,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 4,\allowbreak 0,\allowbreak \,\ldots$ correspond to the number of trailing zeros in the binary representation of $\colorTbar + 1$.%
\footnote{%
As such, in implementation, $\colorH(\colorTbar)$ can be calculated in fast $\mathcal{O}(1)$ using bit-level operations --- e.g., in Python \texttt{(~T \& T-1).bit\_length()} \citep{oeis}.
}
This sequence appears as A007814 in the On-Line Encyclopedia of Integer Sequences \citep{oeis}.
We continue our zero-indexing convention, so $\colorH(0) = 0$, $\colorH(1) = 1$, $\colorH(2) = 0$, etc.

We refer to $\colorH(\colorTbar) = \colorh$ as the ``\textbf{hanoi value}'' of $\colorTbar$ in reference to parallels with the famous ``tower of hanoi'' puzzle \citep{lucas1889jeux}.
On occasion, we abbreviate this term as ``h.v.''

Some intuition for the structure of the Hanoi sequence will benefit the reader.
As depicted in Figure \ref{fig:hanoi-intuition}, the hanoi sequence exhibits recursively-nested fractal structure.
Element 0 appears every 2nd entry, element 1 appears every 4th entry, and in the general case element $\colorh$ appears every $2^{\colorh+1}$th entry.
So, a hanoi value $\colorh$ appears twice as often as value $\colorh + 1$.
Remark, though, that when hanoi value $\colorh$ appears for the first time, the value $\colorh - 1$ has appeared exactly once.
So, we have seen exactly one instance of $\colorh$ and also exactly one instance of $\colorh - 1$.
At this point, the value $\colorh - 2$ has appeared exactly twice and, in general, the value $\colorh - n$ has appeared $2^{n - 1}$ times.

\subsection{Time Epoch $\colort$}
\label{sec:notation-epoch}

Owing to h.v.-based structure, the binary order of magnitude of the elapsed time $\colorT$ plays a useful conceptual role.
We call this value $\colort \sim \log_2(\colorT)$ the \textbf{epoch} of $\colorT$, correcting to begin epoch $\colort=1$ at $\colorT \approx \colorS$.

For the \textit{steady algorithm}, epoch transitions occur immediately \textit{before} each binary order of magnitude $\colorT \geq \colorS - 1$ (e.g.,  $\colorT = 15$).
For the \textit{stretched} and \textit{tilted algorithms}, epoch transitions instead occur exactly at each binary order of magnitude (e.g., $\colorT = 16$) for $\colorT \geq \colorS$.
Formally,
\begin{align*}
\colort &\coloneq \max\Big(\left\lfloor \log_2(\colorT+1) \right\rfloor - \colors + 1, 0\Big) \tag{steady algorithm}\\
&\text{or}\\
\colort &\coloneq \max\Big(\left\lfloor \log_2(\colorT - 1) \right\rfloor - \colors + 1, 0\Big) \tag{stretched/tilted algorithms}.
\end{align*}

As noted above, stretched and tilted algorithms limit consideration to $\colorT < 2^{\colorS}$.
Thus, for these algorithms,
\begin{align*}
\colort &\leq \left\lfloor\log_2(2^{\colorS} - 1)\right\rfloor - \colors + 1 \\
&\leq \colorS - \colors,
\end{align*}
assuming $\colorS \geq 2$.

\subsection{Site Reservations $\colorHcal_{\colort}(\colork)$}
\label{sec:notation-reservation}

Algorithm design is structured around ``reserving'' (setting aside) buffer sites $\colork \in \colorS$ to host data items $\colorTbar$ of a specific hanoi value $\colorH(\colorTbar) = \colorh$, on an epoch-to-epoch-basis.
Denote site $\colork$'s \textbf{hanoi value reservation} during epoch $\colort$ as $\colorHcal_{\colort}(\colork) = \colorh$.%
\footnote{%
A careful reader may wonder if site $\colork$'s hanoi value reservation $\colorHcal_{\colort}(\colork)$ should also be qualified by overall buffer size $\colorS$, in addition to current epoch $\colort$.
Although omited from our notation for brevity, this is indeed the case.%
}%
Note that a data item $\colorTbar \not\in \colort$ may occupy site $\colork$ during epoch $\colort$ with $\colorHcal_{\colort}(\colork) \neq \colorH(\colorTbar)$, having been held over from the previous epoch $\colort - 1$ before being overwriten with an instance of h.v. $\colorh = \colorHcal_{\colort}(\colork)$ during the current epoch $\colort$.

\subsection{Time Meta-epoch $\colortau$}
\label{sec:notation-metaepoch}

In the case of the \textit{stretched} and \textit{tilted} algorithms, it becomes useful to organize a further abstraction on top of time epoch $\colort$: \textbf{meta-epoch} $\colortau$.
We define $\colortau=1$ as beginning at epoch $\colort = 1$, with $\colortau=0$ for epoch $\colort=0$.
As later motivated in Lemma \ref{thm:stretched-meta-epoch}, we define meta-epochs $\colortau\geq1$ as lasting $2^{\colortau} - 1$ epochs.
Under this definition, we have $\colortau\geq1$ as beginning at epoch
\begin{align*}
\min\{\colort \in \colortau\}
&= 1 + \sum_{i=1}^{\colortau - 1} (2^{i} - 1) \\
&= 2^{\colortau} - \colortau.
\end{align*}
For epoch $\colort > 0$, we can calculate the current meta-epoch $\colortau$ exactly as
\begin{align*}
\colortau
=
\begin{cases}
\left\lfloor \log_2(\colort) \right\rfloor + 1 & \text{if } \colort = 2^{\left\lfloor \log_2(\colort) \right\rfloor} - \left\lfloor \log_2(\colort) \right\rfloor \\
\left\lfloor \log_2(\colort) \right\rfloor & \text{otherwise.}
\end{cases}
\end{align*}

Recalling that stretched and tilted algorithms limit $\colort \leq \colorS - \colors$, Supplementary Lemma \ref{thm:meta-epoch-bound} establishes the following upper bounds on $\colortau$,
\begin{align*}
\colortau
&\leq
\min\Big(
  \log_2(\colort + \colors),
  \log_2(\colort) + 1
\Big)
\text{ for } \colort \in 1, 2, \ldots, \colorS - \colors.
\end{align*}
Taking $\colort = \colorS - \colors$, we can also bound $\colortau$ over the stretched and tilted algorithms' domains by
\begin{align*}
\colortau \leq \colors.
\end{align*}

\subsection{Miscellania}

Let the binary floor of a value $x$ be denoted $\left\lfloor x \right\rfloor_\mathrm{bin} = 2^{\left\lfloor \log_2 x \right\rfloor}$.
For binary ceiling, let $\left\lceil x \right\rceil_\mathrm{bin} = 2^{\left\lceil \log_2 x \right\rceil}$.
As a final piece of minutiae, take $2^{\mathbb{N}} = \{2^n : n \in 0, 1, \,\ldots \}$.
