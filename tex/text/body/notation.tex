\section{Preliminaries, Notations, and Terminology} \label{sec:notation}

The core function of proposed algorithms is to dynamically filter out a bounded-size subset of incoming data that, according to a desired \textbf{coverage criterion}, manages the structure of gaps in history created by discarding items.
Incoming data is assumed to arrive on a rolling basis, as a \textbf{data stream} comprised of sequential \textbf{data items} $v_i$.
We assume the data stream to be ephemeral (i.e., ``read once''), and refer to the act of reading an item from the data stream as \textbf{ingesting} it.
As mentioned above, we term this scenario the \textbf{data stream curation problem}.

We consider data items according only to their logical sequence position.
We do not consider data items' actual semantic values or real-time arrival.
We assume data item values as fixed size and thus interchangeable in memory buffer slots.

The remainder of this section will proceed to overview key notations used throughout this work, summarized in Table \ref{tab:notation}.

\input{tab/notation.tex}

\subsection{Buffer Storage $\colorS$}
\label{sec:notation-buffer}

We assume a fixed \textit{number of available buffer sites}, sufficient to store $\colorS$ data items.%
\footnote{%
In associated materials, the fixed-size buffer used to store curated data items is referred to as a ``surface.''
Space-efficient solutions for the stream curation problem under extensible memory capacity have been considered in other work \citep{moreno2024algorithms}.%
}
Proposed algorithms require buffer size $\colorS$ as an even power of two, larger than 4. That is, $\colorS = 2^{\colors}$ for some integer $\colors \in \mathbb{N}_{\geq 2}$.
On occasion, it will become necessary to refer to a specific buffer position $\colork$.
We will take a zero-indexing convention, so $\colork \in [0\twodots\colorS)$.

We consider only one update operation on the buffer: storage of an ingested data item at a buffer site $\colork$.
Under this scheme, control of what data is retained and for how long occurs solely as a consequence of \textit{ingestion site selection} --- picking where (and if) to store incoming data items.
Let $\colorK(\colorT) \in [0\twodots\colorS)\cup\{\nullval\}$ denote the site selection operation to place data item $\colorT$ --- with $\nullval$ denoting a data item dropped without storing.%
\footnote{%
A more exacting notation would reflect that site selection depends on buffer size (i.e., as $\colorK_{\colorS}(\colorT)$), but we omit this in our notation for brevity.
}
A schematic of site selection is provided in Figure \ref{fig:surface-site-ingest}.

As a space-saving optimization, we store only the data items themselves in buffer space --- no metadata (e.g., ingestion time) or data structure components (e.g., indices or pointers) are stored.
This optimization is critical, in particular, when data items are small --- such as single bits or single bytes \citep{moreno2022hereditary}.
Without metadata, however, identifying stored data items requires capability to deduce ingest time solely from buffer position $\colork$.
Figure \ref{fig:ingest-rank-calculation} depicts the role of \textit{site lookup} in calculating ingest times of stored data.

\subsection{Time $\colorT$}
\label{sec:notation-time}

We will refer to each data item's stream sequence index as its \textbf{ingestion time} $\colorTbar$ and the most recent ingestion time as the \textbf{current time} $\colorT$.
We use a zero-indexing convention (the first element of the data stream has ingestion time $\colorTbar=0$).
We assume $\colorT$ to be known for each data ingestion.
Because we are only concerned with the sequence order of data items, and not the values of data items themselves, we will shorthand $\colorTbar$ as referring to $v_{\colorTbar}$ (the data item ingested at that time).

Ideally, data stream curation would support indefinite ingestions, $\colorT \in \mathbb{N}$.
Our proposed \textit{steady curation} algorithm, introduced below, operates in this fashion.
However, our proposed \textit{stretched} and \textit{tilted curation} algorithms accept only $2^{\colorS} - 2$ ingestions.
We expect this capacity to suffice for many applications using even moderately sized buffers.
For instance, a 64-site buffer suffices to ingest items continuously at 5GHz for over 100 years.
As such, we leave behavior for stretched and tilted curation past $2^{\colorS} - 2$ ingests to future work.

For convenience in exposition, note that we formally define and characterize these algorithms only for $\colorT \in [0 \twodots 2^{\colorS - 1})$.
However, in practice, extension to $\colorT \in [0 \twodots 2^{\colorS} - 1)$ that respects established guarantees on curation quality is straightforward.

\subsection{Gap Size $\colorg$}
\label{sec:notation-gapsize}

% Be reminded that \textit{coverage criteria} for retained data items considered here operate solely in terms of items' time indices $\colorTbar$.
We define coverage criteria in terms of \textbf{gap sizes} in the retained record.
Formally, we define gap size as a count of consecutive data items that have been discarded or overwritten.
Let $\colorB_{\colorT}$ denote data items retained in buffer at time $\colorT$ (including $v_{\colorT}$) and $\colorBnot_{\colorT}$ refer to data items discarded (i.e., overwritten) up to that point.
Gap size for record index $\colorTbar \in [0 \twodots \colorT]$ at time $\colorT$ follows as
\begin{align}
\colorG_{\colorT}(\colorTbar)
&\coloneq
\max
\{
  i + j
  \text{ for }
  i, j \in \mathbb{N}
  :
  [\colorTbar-i \twodots \colorTbar+j) \subseteq \colorBnot_{\colorT}
\}.
\label{eqn:gap-size-defn}
\end{align}
Note that if $\colorTbar \in \colorB_{\colorT}$, then $\colorG_{\colorT}(\colorTbar) = 0$.

\subsection{Time Hanoi Value $\colorh$}
\label{sec:notation-hanoi}

As shown in Figure \ref{fig:hanoi-intuition} --- and discussed in greater detail later on --- it happens that the structure of proposed algorithms relies heavily on abstractions based around data items' ingestion time $\colorTbar$.
One foundational abstraction is the corresponding value in the following integer sequence,
\begin{align}
\colorH(\colorTbar)
\coloneq
\max \{ n \in \mathbb{N} : (\colorTbar + 1) \bmod 2^n = 0 \}.
\label{eqn:hanoi-defn}
\end{align}
Refer to $\colorH(\colorTbar) = \colorh$ as the ``\textbf{hanoi value}'' of $\colorTbar$, in reference to parallels with the famous ``tower of hanoi'' puzzle \citep{lucas1889jeux}.
We frequently abbreviate this term as ``\textbf{\hv{}}''

Terms of this sequence, A007814 in the On-Line Encyclopedia of Integer Sequences \citep{oeis}, correspond to the number of trailing zeros in the binary representation of $\colorTbar + 1$.%
\footnote{%
As such, in implementation, $\colorH(\colorTbar)$ can be calculated in fast $\mathcal{O}(1)$ using bit-level operations --- e.g., in Python \texttt{(~T \& T-1).bit\_length()} \citep{oeis}.
}
The first terms are $0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 3,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 2,\allowbreak 0,\allowbreak 1,\allowbreak 0,\allowbreak 4,\allowbreak 0,\allowbreak \;\;\ldots \;\;$.
We continue our zero-indexing convention, so $\colorH(0) = 0$, $\colorH(1) = 1$, $\colorH(2) = 0$, etc.

Some intuition for the structure of the Hanoi sequence will benefit the reader.
As depicted in Figure \ref{fig:hanoi-intuition}, the hanoi sequence exhibits recursively-nested fractal structure.
Element 0 appears every 2nd entry, element 1 appears every 4th entry, and in the general case element $\colorh$ appears every $2^{\colorh+1}$th entry.
So, a hanoi value $\colorh$ appears twice as often as value $\colorh + 1$.
When hanoi value $\colorh$ appears for the first time, the value $\colorh - 1$ has appeared exactly once.
So, we have seen exactly one instance of $\colorh$ and also exactly one instance of $\colorh - 1$.
At this point, the value $\colorh - 2$ has appeared exactly twice and, in general, the value $\colorh - n$ has appeared $2^{n - 1}$ times.

\input{fig/hanoi-intuition.tex}

\subsection{Time Epoch $\colort$}
\label{sec:notation-epoch}

Owing to our algorithms' incorporation of \hv{}-based abstractions, it is useful to track a measure related to binary magnitude of elapsed time $\colorT$ (i.e., $\sim \log_2(\colorT)$).
We call this measure the \textbf{epoch} $\colort$ of time $\colorT$,
\begin{equation}
\colort
\coloneq
\max\Big(\left\lfloor \log_2(\colorT+x) \right\rfloor - \colors + 1,\;\; 0\Big)
\text{ with }
x =
\begin{cases}
1 & \text{for steady algorithm and} \\
0 & \text{for stretched and tilted algorithms.}
\end{cases}
\label{eqn:epoch-defn}
\end{equation}

For the \textit{steady algorithm}, epochs' first time point $\colorT = \min\colortsetofT$  sits one less than an even power of two (e.g.,  $\colorT = 15$).
For the \textit{stretched} and \textit{tilted algorithms}, epochs begin exactly at even powers of two (e.g., $\colorT = 16$) for $\colorT \geq \colorS$.
In both cases, note correction to begin epoch $\colort=1$ at $\colorT \approx \colorS$.

As mentioned above, stretched and tilted algorithms limit consideration to $\colorT < 2^{\colorS - 1}$, so
\begin{align*}
\colort &\leq \left\lfloor\log_2(2^{\colorS - 1} - 1)\right\rfloor - \colors + 1
\leq \colorS - \colors - 1
\end{align*}
assuming $\colorS \geq 4$.
This relation can be understood as arising due to delay of epoch $\colort=1$ to time $\colort=2^{\colors}$.

\subsection{Site Reservations $\colorHcal_{\colort}(\colork)$}
\label{sec:notation-reservation}

Algorithm design is structured around ``reserving'' (setting aside) buffer sites $\colork \in [0 \twodots \colorS)$ to host data items whose time index $\colorTbar$ has a specific \hv{}, $\{\colorTbar : \colorH(\colorTbar) = \colorh \}$, on an epoch-to-epoch-basis.
Denote site $\colork$'s \textbf{hanoi value reservation} during epoch $\colort$ as $\colorHcal_{\colort}(\colork)$.%
\footnote{
A careful reader may wonder if notation for site $\colork$'s hanoi value reservation $\colorHcal_{\colort}(\colork)$ should also be qualified by overall buffer size $\colorS$ as $\colorHcal_{\colort,\colorS}(\colork)$, in addition to current epoch $\colort$.
Although omitted from our notation for brevity, this is indeed the case.
}
Note that a data item $\colorTbar \not\in \colortsetofT$ may occupy site $\colork$ during epoch $\colort$ with $\colorHcal_{\colort}(\colork) \neq \colorH(\colorTbar)$, having been held over from the previous epoch $\colort - 1$ before being overwriten with an instance of \hv{} $\colorh = \colorHcal_{\colort}(\colork)$ during the current epoch $\colort$.

\subsection{Time Meta-epoch $\colortau$}
\label{sec:notation-metaepoch}

In the case of the \textit{stretched} and \textit{tilted} algorithms, it becomes useful to group sequential epochs $\colort$ together as \textbf{meta-epochs} $\colortau$.
We define $\colortau=0$ as corresponding to epoch $\colort=0$.
Meta-epoch $\colortau=1$ therefore begins at epoch $\colort = 1$.
As later motivated in Lemma \ref{thm:stretched-meta-epoch}, we define meta-epochs $\colortau\geq1$ as lasting $2^{\colortau} - 1$ epochs.
Under this definition, we have $\colortau\geq1$ as beginning at epoch
\begin{align}
\min(\colort \in \colortausetoft)
&= 1 + \sum_{i=1}^{\colortau - 1} (2^{i} - 1) \nonumber \\
&= 2^{\colortau} - \colortau.
\label{eqn:meta-epoch-defn}
\end{align}
For epoch $\colort > 0$, we can thus calculate the current meta-epoch $\colortau$ exactly as
\begin{align*}
\colortau
=
\begin{cases}
\left\lfloor \log_2(\colort) \right\rfloor + 1 & \text{if } \colort = 2^{\left\lfloor \log_2(\colort) \right\rfloor} - \left\lfloor \log_2(\colort) \right\rfloor \\
\left\lfloor \log_2(\colort) \right\rfloor & \text{otherwise.}
\end{cases}
\end{align*}

Recalling that stretched and tilted algorithms limit $\colort < \colorS - \colors$, Supplementary Lemma \ref{thm:meta-epoch-bound} establishes the following upper bounds on $\colortau$,
\begin{align*}
\colortau
&\leq
\min\Big(
  \log_2(\colort + \colors),\;\;
  \log_2(\colort) + 1
\Big)
\text{ for } \colort \in [1 \twodots \colorS - \colors).
\end{align*}
Taking $\colort = \colorS - \colors - 1$, we can also bound $\colortau$ over the stretched and tilted algorithms' domains by $\colortau < \colors$.

\subsection{Miscellania}

Let the binary floor of a value $x$ be denoted $\left\lfloor x \right\rfloor_\mathrm{bin} = 2^{\left\lfloor \log_2 x \right\rfloor}$.
For binary ceiling, let $\left\lceil x \right\rceil_\mathrm{bin} = 2^{\left\lceil \log_2 x \right\rceil}$.
As a final piece of minutiae, take $\{2^{\mathbb{N}}\}$ as shorthand for $\{2^n : n \in \mathbb{N} \}$.
