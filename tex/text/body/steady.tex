\section{Steady Algorithm} \label{sec:steady}

The steady criterion seeks to retain data items from time points evenly spread across observed history.
As given in Equation \ref{eqn:steady-cost} in Section \ref{sec:stream-curation-problem}, the steady criterion's cost function is the largest gap size between retained data items, $\mathsf{cost\_steady}(\colorT) = \max\{\colorG_{\colorT}(\colorTbar) : \colorTbar \in [0 \twodots \colorT)\}$.
For a buffer size $\colorS$ and time elapsed $\colorT$, largest gap size can be minimized no lower than
\begin{align}
\mathsf{cost\_steady}(\colorT)
&\geq
\left\lceil
\frac{\colorT - \colorS}{\colorS + 1}
\right\rceil.
% =
% \left\lfloor
% \frac{\colorT}{\colorS + 1}
% \right\rfloor.
\label{eqn:steady-optimal-gap-size}
\end{align}
This section presents a stream curation algorithm designed to support the steady criterion, guaranteeing maximum gap size no worse than
\begin{align*}
\mathsf{cost\_steady}(\colorT)
% &\leq 2^{\colort}
% = 2^{\left\lfloor \log_2(\colorT/\colorS) \right\rfloor + 1} - 1
&\leq 2 \left\lfloor \frac{\colorT}{\colorS} \right\rfloor_{\mathrm{bin}} - 1.
\end{align*}
Disparity from ideal arises because maintaining uniform gap spacing on an ongoing basis is impossible on account of data item discards merging neighboring gaps.

\subsection{Steady Algorithm Strategy}
\label{sec:steady-strategy}

Figure \ref{fig:hanoi-intuition-steady} overviews the proposed algorithm's core strategy, which revolves around prioritizing data item retention according to the \hv{} of the sequence indices, $\colorH(\colorTbar)$.
Specifically, we aim to keep data items with the largest hanoi values.

It turns out that with all data items $\colorH(\colorTbar) > m$ retained, gap size is at most $\colorg \leq 2^m - 1$.
To understand, imagine discarding items with $\colorH(\colorTbar) = 0$.
This action would drop every other item, and increase gap size from 0 to $\colorg \leq 1$.
Then, removing items with $\colorH(\colorTbar) = 1$ would again drop every other item, and increase gap size to $\colorg \leq 3$.
Continuing this pattern to prune successive hanoi values provides well-behaved transitions that gradually increase gap size while maintaining even spacing.

We thus set out to maintain, for a ratcheting threshold $n(\colorT)$, all items $\colorH(\colorTbar) > n(\colorT)$.
(The threshold $n(\colorT)$ must increase over time to ensure space for new high h.v. data items as we encounter them.)
Formally,
\begin{align*}
\mathsf{goal\_steady}
\coloneq \{
\colorTbar \in [0 \twodots \colorT)
: \colorH(\colorTbar) > n(\colorT)
\}.
\end{align*}
In practice, this requires repeatedly discarding all items with lowest \hv{} $\colorH(\colorTbar) = n(\colorT)$ as time elapses.
Supplementary Lemma \ref{thm:steady-hv-geq-epoch} shows that using a threshold of $n(\colorT) = \colort - 1$ fills available buffer space $\colorS$.%
% \footnote{%
% More exactly, $\colorS - 1$ sites are required.
% So, \textit{nearly} all buffer space is needed to store $\{\colorTbar : \colorH(\colorT) \geq \colort\}$.
% In practice, the surplus site can be convenient to store the very first or the very most recent data item.
% }

\subsection{Steady Algorithm Mechanism}
\label{sec:steady-mechanism}

\input{fig/hsurf-steady-intuition}

Each epoch $\colort$, all items with $\colorH(\colorTbar) = \colort - 1$ must be overwritten to make space for new items with \hv{} $\colorh \geq \colort$.
Figure \ref{fig:hsurf-steady-intuition} overviews the layout procedure used to orchestrate replacement of data items with \hv{} $\colorh = \colort - 1$ each epoch.
We divide buffer space into $\colors$ ``bunches,'' themselves divided into ``segments.''
Bunch $i=0$ contains one segment of length $\colors + 1$ sites.
The layout of bunch $i=0$ is a special case, relative to the layout of subsequent bunches $i>0$.
For $i > 0$, bunch $i$ contains $2^{i-1}$ segments.
Although segment count increases across bunches $i > 0$, segment length decreases by 1 each bunch as $\colors - i$.
So, segments in the last bunch contain only one site.
With $\colors$ bunches, available buffer space $\colorS$ is filled by this reservation layout,
\begin{align*}
\colors + \sum_{i=0}^{\colors-1} (\colors - i - 1) \times 2^{i} = 2^{\colors} - 1 = \colorS - 1.
\end{align*}

For each hanoi value $\colorh$, if we store one data item $\colorH(\colorTbar) = \colorh$ per segment, data items with a hanoi value $\colorh$ will touch all segments within exactly one bunch over the course of one epoch.
Bunch 0 will contain the first data item with \hv{} $\colorh$, which is encountered in epoch $\colort=\colorh - \colors$.
Bunch 1 contains the one data item with that \hv{} from epoch $\colort=\colorh - \colors + 2$.
Bunch 2 contains the two data items with \hv{} $\colorh$ from epoch $\colort=\colorh - \colors + 3$.
In general, bunch $i$ will contain data items $\{ \colorTbar \in \lBrace \colort = \colorh - \colors + i + 1 \rBrace : \colorH(\colorTbar) = \colorh \}$.
Segment size (decreasing by one each bunch) is arranged so that one instance of all $\colors - i$ \hv's that have ``progressed'' to bunch $i$ can be stored within each segment in that bunch.

\input{fig/hsurf-steady-implementation}

The particulars of our layout become useful in managing elimination of data items with \hv{} $\colorh = \colort - 1$ during epoch $\colort$.
As noted above, \hv{} $\colort + \colors$ will store exactly one data item in bunch 0 during epoch $\colort > 0$.
This is the same number of data items left by \hv{} $\colort - 1$ in bunch 0 during earlier epoch $\colort - \colors - 1$.
The same correspondence holds in bunch 1, between \hv{} $\colort + \colors - 2$ and \hv{} $\colort - 1$.
Indeed, across all bunches $i>0$, the number of data items left by \hv{} $\colort + \colors - i$ in bunch $i$ equals those left earlier by \hv{} $\colort - 1$.

As shown in Figure \ref{fig:hsurf-steady-implementation}, we can take advantage of one-to-one correspondence between incoming data items and data items of \hv{} $\colorh=\colort-1$ to choreograph clean elimination of \hv{} $\colorh=\colort-1$ by overwrites each epoch.
In determining storage site $\colork$ for ingest $\colorTbar$, we map incoming data items with \hv{} $\colorh \geq \colort$ over items $\colorh = \colort - 1$ slated for elimination by placing them at segment positions $\colorh$ modulus segment size.
The number of \hv{} instances $\colorh = \colorH(\colorTbar)$ already seen, which can be calculated $\mathcal{O}(1)$, identifies the segment where data item $\colorTbar$ should be stored.
Lemma \ref{thm:steady-hv-elimination} verifies the behavior of this procedure.

\input{alg/steady-site-selection}

Algorithm \ref{alg:steady-site-selection} provides a step-by-step listing of site selection calculation $\colorK(\colorT)$, which is $\mathcal{O}(1)$.
Site lookup $\colorL(\colorT)$ is provided in supplementary material, as Algorithm \ref{alg:steady-time-lookup}.
Reference Python implementations appear in Supplementary Listings \ref{lst:steady_site_selection.py} and \ref{lst:steady_time_lookup.py}, as well as accompanying tests.
Lookup of ingest time $\colorTbar$ for data item at $\colork$ at time $\colorT$ boils down to decoding its segment/bunch indices and checking whether (if slated) it has yet been replaced during the current epoch $\colort$.
Calculation of site lookup $\colorL(\colorTbar) = \colorTbar_{\colork=0},\;\; \colorTbar_{\colork=1},\;\; \ldots,\;\; \colorTbar_{\colork=\colorS-1}$ proceeds in $\mathcal{O}(\colorS)$ time.

\subsection{Steady Algorithm Criterion Satisfaction}
\label{sec:stready-satisfaction}

In this final subsection, we establish an upper bound on $\mathsf{cost\_steady}(\colorT)$ for a buffer of size $\colorS$ at time $\colorT$ under the proposed steady curation algorithm.
Figure \ref{fig:hsurf-steady-implementation-satisfaction} plots an example of actual worst gap size over time under this algorithm.

\input{thm/steady-gap-size}
