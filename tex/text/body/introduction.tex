\section{Introduction} \label{sec:introduction}

Within the domain of high-performance computing (HPC), efficient algorithms for analyzing and summarizing data streams are key in contending with the ever-increasing volume and velocity of data generation.
In recent years, explosive growth AI/ML workloads has fueled the emergence of a rich ecosystem of highly-capable, specialized hardware accelerator platforms.
Although GPGPU computing has long been most prominent in this space, a broader, highly diverse set of hardware architectures are being fielded by startup market players.
Notable emerging AI/ML hardware accelerator platforms include the Cerebras Systems' Wafer-Scale Engine \citep{lie2023cerebras}, Graphcore's Intelligence Processing Unit \citep{gepner2024performance}, Tenstorrent's Tensix processors \citep{vasiljevic2021compute}, and Groq's GropChip \citep{abts2022groq}.
Pursuing an aggressive scale-out paradigm, such platforms bring hundreds, thousands, or --- in the case of the Wafer-Scale Engine --- hundreds of thousands of processing elements to bear within a single silicon die.

Although these emerging AI/ML hardware accelerators harbor immense potential for general-purpose HPC applications, realizing their benefit will require substantial adaptations to satisfy constraints imposed by their unconventional hardware architectures.
One fundamental manner in which these accelerator devices differ from typical CPU-based hardware is with respect to memory locality.
Rather than exposing a high-capacity shared memory space backed by hardware-level fetching and caching, emerging AI/ML hardware accelerator platforms tend to rely on explicit synchronization or message-passing steps to relay data between processor elements and device-to-host.
As such, available directly-addressable memory capacity can be very small, comprising just processing elements' attached on-chip memory banks.
At the high end, Tenstorrent's Grayskull device and GraphCore's recent Colossus MK2 provide on-chip memory of just 1MB and 612kb, respectively, per processing element \citep{vasiljevic2021compute,gepner2024performance}.
By contrast, Cerebras and Groq's hardware each furnish less than 50kb per processing element \citep{lie2023cerebras,abts2022groq}.

Forward-time simulations exploiting a high degree of locality (e.g., stencil-based methods) have been identified as a prime use case for AI/ML accelerators \citep{jacquelin2022scalable,brown2023exploring,brown2024accelerating,louw2021using}.
To export generated time series data from device to host, such simulation kernels must budget output within local memory capacity and available device-to-host bandwidth.
Where flexibility in levels of output detail is acceptable, dynamic coarsening approaches can be applied to prioritize available capacity based on runtime conditions.

Feasibility of such an approach, however, requires lightweight \textit{in situ} stream processing techniques.
% capable of dynamically recording an indeterminate time interval within fixed storage capacity.
Appropriate coarsening approaches are, of course, highly use-case dependent, including possibilities such as rolling summary statistic calculations \citep{lin2004continuously}, on-the-fly data clustering \citep{silva2013data}, live anomaly detection \citep{cai2004maids}, and rolling event frequency estimation \citep{manku2002approximate}.
Here, we focus on a single core sketching operation: downsampling via thinning, in which a collection of data items comprising a systematic, deterministic temporal cross section of elapsed stream history is dynamically curated.
In particular, we explore the suitability of algorithms generalizing the common ring buffer data structure to carry out this ``stream curation'' task  within resource-constrained contexts \citep{gunther2014compressing}.

Our work comprises two primary contributions:
\begin{enumerate}
\item introduction of a novel ``tilted'' generalized ring buffer algorithm implementing recency-proportional sample composition, and
\item empirical evaluation of on-hardware performance characteristics for generalized ring buffer algorithms and alternate approaches using a model resource-constrained platform.
\end{enumerate}
Presentation of the former is notable in developing a conceptual framework divergent from existing work \citep{gunther2014compressing}, applying binary divisors as the basis for composing retained items.

Over the remainder of the introduction, we will formalize objectives to evaluate ``stream curation'' composition, introduce the generalized ring buffer approach, and review related work.

\subsection{Stream Curation}
\label{sec:stream-curation-problem}

Our work concerns online sampling of discrete data items from a one-dimensional data stream, a task we term ``stream curation.''
We assume a fixed storage capacity; thus, once reached, storing any new data item requires discarding another earlier-retained item.
Maintaining a representative trace of stream history, therefore, involves thinning decisions to ``curate'' an appropriate collection of retained stream items.%
\footnote{%
Note that stream curation should be considered orthogonal to the question of $\ell_p$ sampling (e.g., $\ell_0$ or $\ell_1$ sampling) in that the stream curation objective is to optimize for deterministic temporal balance rather than statistical properties of stochastic composition, which provides advantages in guaranteeing predictable, systematic coverage over temporal history.
With regard to $\ell_p$ sampling, we refer the reader to well-established online techniques to extract $\ell_p$-representative samples over stream distributions such as reservoir sampling, sketching, and hash-based methods \citep{gaber2005mining,muthukrishnan2005data,cormode2019lp}.
}
This task becomes challenging where satisfaction of curation objectives must be interposed across sequential points in time.
In practice, such fully-online curation becomes necessary when either (a) stream records are consulted frequently or (b) time point(s) for which stream records are needed are not known \textit{a priori} (e.g., query- or trigger-driven events).

We consider the quality of a retained collection's coverage over stream history solely in terms of the timepoints (i.e., sequence positions) of retained data items.
As such, under this timepoint-based framing, our discussion will entirely disregard data items' semantic values.

\input{fig/criteria-intuition}

We treat two conventional requirements on curated data: steady composition and tilted composition.
The first, \textit{{steady}} composition, seeks a sample spaced uniformly across elapsed stream history.
The second, \textit{{tilted}} composition, proportionally prioritizes recent data items.
Figure \ref{fig:criteria-intuition} contrasts optimal sample compositions under each.

Given the generality of the tilted and steady curation objectives, related concepts appear in a wide variety of related data stream work, reviewed in Section \ref{sec:prior-work} \citep{aggarwal2003framework,han2005stream}.
Appropriate composition of retained data will vary from application to application, depending on context and objectives.

%Under steady retention, retained items should be spaced evenly across time;
%under tilted retention, spacing between items should scale proportionally with age.


%Existing work on generalized ring buffer, introduced below, provides steady curation.
%Extensions developed on this work target tilted curation.

As detailed further in Section \ref{sec:notation}, we formalize steady and tilted stream curation objectives via cost functions on ``gap size'' $\colorG_{\colorT}(\colorTbar)$ in the curated record, counting contiguous discarded data items around timepoint $\colorTbar$ at logical time $\colorT$,
\begin{empheq}[left={\hspace{1.5in}\displaystyle \mathsf{cost}(\colorT) \coloneq %\empheqlbrace
}]{align}
% \begin{align}
% \mathsf{cost\_steady}(\colorT) \coloneq
\max_{\colorTbar \in [0\twodots\colorT)} \colorG_{\colorT}(\colorTbar) &&\text{for \textit{``steady''} curation,}  &&& ~ &&& ~
  \label{eqn:steady-cost}
 \\
% &\max_{\colorTbar \in [1\twodots\colorT)} \frac{\colorG_{\colorT}(\colorTbar)}{\colorTbar} &&\text{for \textit{``stretched''} curation, and}  &&& ~ &&& ~ \label{eqn:stretched-cost} \\
&\max_{\colorTbar \in [0\twodots\colorT - 1)} \frac{\colorG_{\colorT}(\colorTbar)}{\colorT - 1 - \colorTbar} &&\text{for \textit{``tilted''} curation,}  &&& ~ &&& ~ \label{eqn:tilted-cost}
\end{empheq}
% \end{align}
Within this framework, guarantees on curation quality devise an upper bound $\mathsf{bound}(\colorT)$ on cost $\mathsf{cost}(\colorT)$.

\subsection{Generalized Ring Buffer}

\input{fig/curation-ingest-lookup.tex}

A commonplace data structure, ring buffers provide a fast, space-efficient, and straightforward mechanism to curate last-$n$ samples from a data stream on a rolling basis \citep{dusseau2018operating}.
Classically, ring buffers operate by arranging data storage in a simple cyclical pattern over buffer space, as shown in Figure \ref{fig:curation-ingest-lookup:ring}.
A key feature driving the simplicity and efficiency of the ring buffer data structure is the coupling of storage and deletion operations, wherein overwrites implicitly eliminate stale data.

As depicted in \ref{fig:curation-ingest-lookup:steady}, applying alternate data storage patterns over buffer space can enable sophisticated curation behavior beyond last-$n$ retention \citep{gunther2014compressing}.
With sufficient care, design of such data storage algorithms can carry forward attractive qualities of the naive ring buffer,
\begin{itemize}
\item a constant-size, contiguous memory footprint that is fully utilized,
\item avoidance of bookkeeping overhead (e.g., timestamps, pointers, \item strict constant-time update operations (``site selection''  in Figure \ref{fig:curation-ingest-lookup}), and
\item efficient origin time attributability for all stored data (``lookup''  in Figure \ref{fig:curation-ingest-lookup}).
\end{itemize}

Although these properties are highly promising for resource-constrained operations, the generalized ring buffer approach has yet to be explored in the application-oriented stream processing literature.
In original work establishing the subject, \citet{gunther2014compressing} demonstrates a ring buffer algorithm providing even-spaced \textit{steady curation}, through an approach based in number theory that leverages arithmatic properties of strictly doubling sampling intervals modulus odd buffer size.
In this work, we develop an alternate design framework based around 2-adic valuations as a means to devise a complementary ring buffer algorithm supporting \textit{tilted curation}, where collection composition is approximately recency proportional.
While the scope of present work focuses on core thinning operations, we note that alternate summarization strategies may be pursued under the generalized ring buffer approach --- such as summation, averaging, tracking minima/maxima, or random sampling within aggregation intervals \citep{gunther2014compressing}.

\subsection{Related Work}

Owing to dimension reduction's fundamental role in supporting more advanced data stream operations, substantial work exists concerning downsampling via temporal binning \citep{sibai2016sampling,gama2007data}.
Notably, schemes for steady (``equi-segmented'') and tilted (``vari-segmented'') retention appear in \citep{zhao2005generalized}, with the latter resembling additional ``pyramidal,'' ``logarithmic,'' and ``tilted'' time window schemes appearing elsewhere \citep{aggarwal2003framework,han2005stream,giannella2003mining,phithakkitnukoon2010recent}.
Work on ``amnesic approximation'' is notable in providing a generalized scheme for downsampling satisfying an arbitrary temporal cost function \citep{palpanas2004online}.
Although congruities exist in objectives and aspects of algorithm structure, this body of existing work applies iterative, stateful approaches less suited to resource-constrained use cases.

A key motivating use case of work presented here has been in development of decentralized methods for tracking ancestry trees in highly-distributed agent-based evolution simulations \citep{moreno2022hereditary}.
These methods work by appending checkpoint data to agent genomes each generation;
similarity among checkpoint records can then be used to estimate the duration of common ancestry.
For this use case, stream curation is necessary to rein in otherwise unbounded growth of generational checkpoint records.
As downsampling introduces uncertainty to estimates of lineage divergence, systematic spacing of retained checkpoints across generational history is crucial to inference quality \citet{moreno2024guide}.
Given the use of individual checkpoint values as small as single bits and the fact that records must be migrated between processors alongside their corresponding agents, ensuring compact, fixed-length, contiguous storage is particularly critical.

Indeed, generalized ring buffer approaches have enabled this methodology to scale up using AI/ML accelerator hardware for experiments scaling up to the Cerebras Wafer-Scale Engine \citep{moreno2024trackable}
More broadly, beyond the acute resource-constrained scope of AI/ML hardware devices,
A need for lightweight data stream processing techniques exists beyond these accelerator domains, as well, given the increasing prominence of RDMA \citep{wang2024survey} and broader growth of compute capacity relative to memory capacity \citep{qureshi2014memory}.
Outside of high-performance computing, straightforward application of stream curation is in unattended or sporadically uplinked sensor devices, which must record incoming observation streams on an indefinite or indeterminate basis, with limited memory capacity \citep{jain2022survey}.
Lightweight data stream processing methods are also applicable to embedded applications, such as distributed sensor networks and \citep{elnahrawy2003research},
There has been some work to extend the record capacity of data loggers through application-specific online compression algorithms \citep{hadiatna2016design}.


Although not covered here, in other preliminary work we have also investigated a broader suite of ``DStream'' algorithms beyond the ``tilted'' algorithm presented here, including an approach that \textit{skews older} over elapsed history (``\textit{stretched}'' algorithm) and an alternate approach to steady curation compared to existing approaches \citep{moreno2024structured}.
